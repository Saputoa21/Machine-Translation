{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Saputoa21/Machine-Translation/blob/main/seq2seq_NMT_MTMA2025s_v2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hNLGZS6Ii_YE"
      },
      "source": [
        "# Seq2seq NMT with RNN\n",
        "\n",
        "\n",
        "[Neural Machine Translation by Jointly Learning to Align and Translate](https://arxiv.org/abs/1409.0473)\n",
        "\n",
        "**NOTE:**\n",
        "\n",
        "-  use clean bpe data\n",
        "-  use a piece of training data during coding or low in credits\n",
        "\n",
        "You have to implement:\n",
        "\n",
        "- Encoder\n",
        "- Attention (Bahdanau)\n",
        "- training loop\n",
        "- extra: BLEU model selection\n",
        "\n",
        "Goal:\n",
        "\n",
        "- Loss in training, validation and test\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torch==2.3.0\n",
        "!pip install torchtext==0.18"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FvIhSmCUcDN4",
        "outputId": "bca9c485-3a85-4ffe-c92a-6f17eb990537"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torch==2.3.0\n",
            "  Downloading torch-2.3.0-cp311-cp311-manylinux1_x86_64.whl.metadata (26 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch==2.3.0) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from torch==2.3.0) (4.13.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from torch==2.3.0) (1.13.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch==2.3.0) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch==2.3.0) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch==2.3.0) (2025.3.2)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch==2.3.0)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch==2.3.0)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch==2.3.0)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch==2.3.0)\n",
            "  Downloading nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch==2.3.0)\n",
            "  Downloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch==2.3.0)\n",
            "  Downloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch==2.3.0)\n",
            "  Downloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch==2.3.0)\n",
            "  Downloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch==2.3.0)\n",
            "  Downloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-nccl-cu12==2.20.5 (from torch==2.3.0)\n",
            "  Downloading nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl.metadata (1.8 kB)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch==2.3.0)\n",
            "  Downloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting triton==2.3.0 (from torch==2.3.0)\n",
            "  Downloading triton-2.3.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.4 kB)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.11/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch==2.3.0) (12.5.82)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch==2.3.0) (3.0.2)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy->torch==2.3.0) (1.3.0)\n",
            "Downloading torch-2.3.0-cp311-cp311-manylinux1_x86_64.whl (779.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m779.2/779.2 MB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.6/410.6 MB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.1/14.1 MB\u001b[0m \u001b[31m115.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m98.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m823.6/823.6 kB\u001b[0m \u001b[31m52.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m731.7/731.7 MB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.6/121.6 MB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.5/56.5 MB\u001b[0m \u001b[31m13.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.2/124.2 MB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.0/196.0 MB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m176.2/176.2 MB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading triton-2.3.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (168.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m168.1/168.1 MB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: triton, nvidia-nvtx-cu12, nvidia-nccl-cu12, nvidia-cusparse-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusolver-cu12, nvidia-cudnn-cu12, torch\n",
            "  Attempting uninstall: triton\n",
            "    Found existing installation: triton 3.2.0\n",
            "    Uninstalling triton-3.2.0:\n",
            "      Successfully uninstalled triton-3.2.0\n",
            "  Attempting uninstall: nvidia-nvtx-cu12\n",
            "    Found existing installation: nvidia-nvtx-cu12 12.4.127\n",
            "    Uninstalling nvidia-nvtx-cu12-12.4.127:\n",
            "      Successfully uninstalled nvidia-nvtx-cu12-12.4.127\n",
            "  Attempting uninstall: nvidia-nccl-cu12\n",
            "    Found existing installation: nvidia-nccl-cu12 2.21.5\n",
            "    Uninstalling nvidia-nccl-cu12-2.21.5:\n",
            "      Successfully uninstalled nvidia-nccl-cu12-2.21.5\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 2.6.0+cu124\n",
            "    Uninstalling torch-2.6.0+cu124:\n",
            "      Successfully uninstalled torch-2.6.0+cu124\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchvision 0.21.0+cu124 requires torch==2.6.0, but you have torch 2.3.0 which is incompatible.\n",
            "torchaudio 2.6.0+cu124 requires torch==2.6.0, but you have torch 2.3.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.20.5 nvidia-nvtx-cu12-12.1.105 torch-2.3.0 triton-2.3.0\n",
            "Collecting torchtext==0.18\n",
            "  Downloading torchtext-0.18.0-cp311-cp311-manylinux1_x86_64.whl.metadata (7.9 kB)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from torchtext==0.18) (4.67.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from torchtext==0.18) (2.32.3)\n",
            "Requirement already satisfied: torch>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from torchtext==0.18) (2.3.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torchtext==0.18) (2.0.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=2.3.0->torchtext==0.18) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from torch>=2.3.0->torchtext==0.18) (4.13.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from torch>=2.3.0->torchtext==0.18) (1.13.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=2.3.0->torchtext==0.18) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.3.0->torchtext==0.18) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=2.3.0->torchtext==0.18) (2025.3.2)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch>=2.3.0->torchtext==0.18) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch>=2.3.0->torchtext==0.18) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch>=2.3.0->torchtext==0.18) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.11/dist-packages (from torch>=2.3.0->torchtext==0.18) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.11/dist-packages (from torch>=2.3.0->torchtext==0.18) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.11/dist-packages (from torch>=2.3.0->torchtext==0.18) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.11/dist-packages (from torch>=2.3.0->torchtext==0.18) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.11/dist-packages (from torch>=2.3.0->torchtext==0.18) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.11/dist-packages (from torch>=2.3.0->torchtext==0.18) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /usr/local/lib/python3.11/dist-packages (from torch>=2.3.0->torchtext==0.18) (2.20.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch>=2.3.0->torchtext==0.18) (12.1.105)\n",
            "Requirement already satisfied: triton==2.3.0 in /usr/local/lib/python3.11/dist-packages (from torch>=2.3.0->torchtext==0.18) (2.3.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.11/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=2.3.0->torchtext==0.18) (12.5.82)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->torchtext==0.18) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->torchtext==0.18) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->torchtext==0.18) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->torchtext==0.18) (2025.4.26)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=2.3.0->torchtext==0.18) (3.0.2)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy->torch>=2.3.0->torchtext==0.18) (1.3.0)\n",
            "Downloading torchtext-0.18.0-cp311-cp311-manylinux1_x86_64.whl (2.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m33.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: torchtext\n",
            "Successfully installed torchtext-0.18.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "qxTE-EePi_YH"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "import random\n",
        "import time"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "dKtvwA_Rji-B"
      },
      "outputs": [],
      "source": [
        "#if you dont have bpe data use sacremoese tokenizer\n",
        "#!pip install sacremoses"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#which libraries are we using!!?\n",
        "!pip freeze > requirements.txt"
      ],
      "metadata": {
        "id": "Xr1-PPWBrPxl"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!cat requirements.txt"
      ],
      "metadata": {
        "id": "v1iMgKrDrai0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "29ec763e-8b03-4356-8a2a-451bca076cd5"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "absl-py==1.4.0\n",
            "accelerate==1.6.0\n",
            "aiohappyeyeballs==2.6.1\n",
            "aiohttp==3.11.15\n",
            "aiosignal==1.3.2\n",
            "alabaster==1.0.0\n",
            "albucore==0.0.24\n",
            "albumentations==2.0.6\n",
            "ale-py==0.11.0\n",
            "altair==5.5.0\n",
            "annotated-types==0.7.0\n",
            "antlr4-python3-runtime==4.9.3\n",
            "anyio==4.9.0\n",
            "argon2-cffi==23.1.0\n",
            "argon2-cffi-bindings==21.2.0\n",
            "array_record==0.7.2\n",
            "arviz==0.21.0\n",
            "astropy==7.0.2\n",
            "astropy-iers-data==0.2025.5.12.0.38.29\n",
            "astunparse==1.6.3\n",
            "atpublic==5.1\n",
            "attrs==25.3.0\n",
            "audioread==3.0.1\n",
            "autograd==1.8.0\n",
            "babel==2.17.0\n",
            "backcall==0.2.0\n",
            "backports.tarfile==1.2.0\n",
            "beautifulsoup4==4.13.4\n",
            "betterproto==2.0.0b6\n",
            "bigframes==2.4.0\n",
            "bigquery-magics==0.9.0\n",
            "bleach==6.2.0\n",
            "blinker==1.9.0\n",
            "blis==1.3.0\n",
            "blobfile==3.0.0\n",
            "blosc2==3.3.2\n",
            "bokeh==3.7.3\n",
            "Bottleneck==1.4.2\n",
            "bqplot==0.12.44\n",
            "branca==0.8.1\n",
            "build==1.2.2.post1\n",
            "CacheControl==0.14.3\n",
            "cachetools==5.5.2\n",
            "catalogue==2.0.10\n",
            "certifi==2025.4.26\n",
            "cffi==1.17.1\n",
            "chardet==5.2.0\n",
            "charset-normalizer==3.4.2\n",
            "chex==0.1.89\n",
            "clarabel==0.10.0\n",
            "click==8.2.0\n",
            "cloudpathlib==0.21.0\n",
            "cloudpickle==3.1.1\n",
            "cmake==3.31.6\n",
            "cmdstanpy==1.2.5\n",
            "colorcet==3.1.0\n",
            "colorlover==0.3.0\n",
            "colour==0.1.5\n",
            "community==1.0.0b1\n",
            "confection==0.1.5\n",
            "cons==0.4.6\n",
            "contourpy==1.3.2\n",
            "cramjam==2.10.0\n",
            "cryptography==43.0.3\n",
            "cuda-python==12.6.2.post1\n",
            "cudf-cu12 @ https://pypi.nvidia.com/cudf-cu12/cudf_cu12-25.2.1-cp311-cp311-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl\n",
            "cudf-polars-cu12==25.2.2\n",
            "cufflinks==0.17.3\n",
            "cuml-cu12==25.2.1\n",
            "cupy-cuda12x==13.3.0\n",
            "curl_cffi==0.10.0\n",
            "cuvs-cu12==25.2.1\n",
            "cvxopt==1.3.2\n",
            "cvxpy==1.6.5\n",
            "cycler==0.12.1\n",
            "cyipopt==1.5.0\n",
            "cymem==2.0.11\n",
            "Cython==3.0.12\n",
            "dask==2024.12.1\n",
            "dask-cuda==25.2.0\n",
            "dask-cudf-cu12==25.2.2\n",
            "dask-expr==1.1.21\n",
            "dataproc-spark-connect==0.7.3\n",
            "datascience==0.17.6\n",
            "datasets==2.14.4\n",
            "db-dtypes==1.4.3\n",
            "dbus-python==1.2.18\n",
            "debugpy==1.8.0\n",
            "decorator==4.4.2\n",
            "defusedxml==0.7.1\n",
            "diffusers==0.33.1\n",
            "dill==0.3.7\n",
            "distributed==2024.12.1\n",
            "distributed-ucxx-cu12==0.42.0\n",
            "distro==1.9.0\n",
            "dlib==19.24.6\n",
            "dm-tree==0.1.9\n",
            "docker-pycreds==0.4.0\n",
            "docstring_parser==0.16\n",
            "docutils==0.21.2\n",
            "dopamine_rl==4.1.2\n",
            "duckdb==1.2.2\n",
            "earthengine-api==1.5.15\n",
            "easydict==1.13\n",
            "editdistance==0.8.1\n",
            "eerepr==0.1.2\n",
            "einops==0.8.1\n",
            "en_core_web_sm @ https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.8.0/en_core_web_sm-3.8.0-py3-none-any.whl#sha256=1932429db727d4bff3deed6b34cfc05df17794f4a52eeb26cf8928f7c1a0fb85\n",
            "entrypoints==0.4\n",
            "et_xmlfile==2.0.0\n",
            "etils==1.12.2\n",
            "etuples==0.3.9\n",
            "Farama-Notifications==0.0.4\n",
            "fastai==2.7.19\n",
            "fastcore==1.7.29\n",
            "fastdownload==0.0.7\n",
            "fastjsonschema==2.21.1\n",
            "fastprogress==1.0.3\n",
            "fastrlock==0.8.3\n",
            "filelock==3.18.0\n",
            "firebase-admin==6.8.0\n",
            "Flask==3.1.1\n",
            "flatbuffers==25.2.10\n",
            "flax==0.10.6\n",
            "folium==0.19.5\n",
            "fonttools==4.58.0\n",
            "frozendict==2.4.6\n",
            "frozenlist==1.6.0\n",
            "fsspec==2025.3.2\n",
            "future==1.0.0\n",
            "gast==0.6.0\n",
            "gcsfs==2025.3.2\n",
            "GDAL==3.6.4\n",
            "gdown==5.2.0\n",
            "geemap==0.35.3\n",
            "geocoder==1.38.1\n",
            "geographiclib==2.0\n",
            "geopandas==1.0.1\n",
            "geopy==2.4.1\n",
            "gin-config==0.5.0\n",
            "gitdb==4.0.12\n",
            "GitPython==3.1.44\n",
            "glob2==0.7\n",
            "google==2.0.3\n",
            "google-ai-generativelanguage==0.6.15\n",
            "google-api-core==2.24.2\n",
            "google-api-python-client==2.169.0\n",
            "google-auth==2.38.0\n",
            "google-auth-httplib2==0.2.0\n",
            "google-auth-oauthlib==1.2.2\n",
            "google-cloud-aiplatform==1.92.0\n",
            "google-cloud-bigquery==3.32.0\n",
            "google-cloud-bigquery-connection==1.18.2\n",
            "google-cloud-bigquery-storage==2.31.0\n",
            "google-cloud-core==2.4.3\n",
            "google-cloud-dataproc==5.18.1\n",
            "google-cloud-datastore==2.21.0\n",
            "google-cloud-firestore==2.20.2\n",
            "google-cloud-functions==1.20.3\n",
            "google-cloud-iam==2.19.0\n",
            "google-cloud-language==2.17.1\n",
            "google-cloud-resource-manager==1.14.2\n",
            "google-cloud-spanner==3.54.0\n",
            "google-cloud-storage==2.19.0\n",
            "google-cloud-translate==3.20.2\n",
            "google-colab @ file:///colabtools/dist/google_colab-1.0.0.tar.gz\n",
            "google-crc32c==1.7.1\n",
            "google-genai==1.15.0\n",
            "google-generativeai==0.8.5\n",
            "google-pasta==0.2.0\n",
            "google-resumable-media==2.7.2\n",
            "googleapis-common-protos==1.70.0\n",
            "googledrivedownloader==1.1.0\n",
            "graphviz==0.20.3\n",
            "greenlet==3.2.2\n",
            "grpc-google-iam-v1==0.14.2\n",
            "grpc-interceptor==0.15.4\n",
            "grpcio==1.71.0\n",
            "grpcio-status==1.71.0\n",
            "grpclib==0.4.8\n",
            "gspread==6.2.0\n",
            "gspread-dataframe==4.0.0\n",
            "gym==0.25.2\n",
            "gym-notices==0.0.8\n",
            "gymnasium==1.1.1\n",
            "h11==0.16.0\n",
            "h2==4.2.0\n",
            "h5netcdf==1.6.1\n",
            "h5py==3.13.0\n",
            "hdbscan==0.8.40\n",
            "hf_transfer==0.1.9\n",
            "highspy==1.10.0\n",
            "holidays==0.72\n",
            "holoviews==1.20.2\n",
            "hpack==4.1.0\n",
            "html5lib==1.1\n",
            "httpcore==1.0.9\n",
            "httpimport==1.4.1\n",
            "httplib2==0.22.0\n",
            "httpx==0.28.1\n",
            "huggingface-hub==0.31.2\n",
            "humanize==4.12.3\n",
            "hyperframe==6.1.0\n",
            "hyperopt==0.2.7\n",
            "ibis-framework==9.5.0\n",
            "idna==3.10\n",
            "imageio==2.37.0\n",
            "imageio-ffmpeg==0.6.0\n",
            "imagesize==1.4.1\n",
            "imbalanced-learn==0.13.0\n",
            "immutabledict==4.2.1\n",
            "importlib_metadata==8.7.0\n",
            "importlib_resources==6.5.2\n",
            "imutils==0.5.4\n",
            "inflect==7.5.0\n",
            "iniconfig==2.1.0\n",
            "intel-cmplr-lib-ur==2025.1.1\n",
            "intel-openmp==2025.1.1\n",
            "ipyevents==2.0.2\n",
            "ipyfilechooser==0.6.0\n",
            "ipykernel==6.17.1\n",
            "ipyleaflet==0.19.2\n",
            "ipyparallel==8.8.0\n",
            "ipython==7.34.0\n",
            "ipython-genutils==0.2.0\n",
            "ipython-sql==0.5.0\n",
            "ipytree==0.2.2\n",
            "ipywidgets==7.7.1\n",
            "itsdangerous==2.2.0\n",
            "jaraco.classes==3.4.0\n",
            "jaraco.context==6.0.1\n",
            "jaraco.functools==4.1.0\n",
            "jax==0.5.2\n",
            "jax-cuda12-pjrt==0.5.1\n",
            "jax-cuda12-plugin==0.5.1\n",
            "jaxlib==0.5.1\n",
            "jeepney==0.9.0\n",
            "jieba==0.42.1\n",
            "Jinja2==3.1.6\n",
            "jiter==0.9.0\n",
            "joblib==1.5.0\n",
            "jsonpatch==1.33\n",
            "jsonpickle==4.0.5\n",
            "jsonpointer==3.0.0\n",
            "jsonschema==4.23.0\n",
            "jsonschema-specifications==2025.4.1\n",
            "jupyter-client==6.1.12\n",
            "jupyter-console==6.1.0\n",
            "jupyter-leaflet==0.19.2\n",
            "jupyter-server==1.16.0\n",
            "jupyter_core==5.7.2\n",
            "jupyter_kernel_gateway @ git+https://github.com/googlecolab/kernel_gateway@b134e9945df25c2dcb98ade9129399be10788671\n",
            "jupyterlab_pygments==0.3.0\n",
            "jupyterlab_widgets==3.0.15\n",
            "kaggle==1.7.4.5\n",
            "kagglehub==0.3.12\n",
            "keras==3.8.0\n",
            "keras-hub==0.18.1\n",
            "keras-nlp==0.18.1\n",
            "keyring==25.6.0\n",
            "keyrings.google-artifactregistry-auth==1.1.2\n",
            "kiwisolver==1.4.8\n",
            "langchain==0.3.25\n",
            "langchain-core==0.3.59\n",
            "langchain-text-splitters==0.3.8\n",
            "langcodes==3.5.0\n",
            "langsmith==0.3.42\n",
            "language_data==1.3.0\n",
            "launchpadlib==1.10.16\n",
            "lazr.restfulclient==0.14.4\n",
            "lazr.uri==1.0.6\n",
            "lazy_loader==0.4\n",
            "libclang==18.1.1\n",
            "libcudf-cu12 @ https://pypi.nvidia.com/libcudf-cu12/libcudf_cu12-25.2.1-py3-none-manylinux_2_28_x86_64.whl\n",
            "libcugraph-cu12==25.2.0\n",
            "libcuml-cu12==25.2.1\n",
            "libcuvs-cu12==25.2.1\n",
            "libkvikio-cu12==25.2.1\n",
            "libpysal==4.13.0\n",
            "libraft-cu12==25.2.0\n",
            "librosa==0.11.0\n",
            "libucx-cu12==1.18.1\n",
            "libucxx-cu12==0.42.0\n",
            "lightgbm @ file:///tmp/lightgbm/LightGBM/dist/lightgbm-4.5.0-py3-none-linux_x86_64.whl\n",
            "linkify-it-py==2.0.3\n",
            "llvmlite==0.43.0\n",
            "locket==1.0.0\n",
            "logical-unification==0.4.6\n",
            "lxml==5.4.0\n",
            "Mako==1.1.3\n",
            "marisa-trie==1.2.1\n",
            "Markdown==3.8\n",
            "markdown-it-py==3.0.0\n",
            "MarkupSafe==3.0.2\n",
            "matplotlib==3.10.0\n",
            "matplotlib-inline==0.1.7\n",
            "matplotlib-venn==1.1.2\n",
            "mdit-py-plugins==0.4.2\n",
            "mdurl==0.1.2\n",
            "miniKanren==1.0.3\n",
            "missingno==0.5.2\n",
            "mistune==3.1.3\n",
            "mizani==0.13.5\n",
            "mkl==2025.0.1\n",
            "ml-dtypes==0.4.1\n",
            "mlxtend==0.23.4\n",
            "more-itertools==10.7.0\n",
            "moviepy==1.0.3\n",
            "mpmath==1.3.0\n",
            "msgpack==1.1.0\n",
            "multidict==6.4.3\n",
            "multipledispatch==1.0.0\n",
            "multiprocess==0.70.15\n",
            "multitasking==0.0.11\n",
            "murmurhash==1.0.12\n",
            "music21==9.3.0\n",
            "namex==0.0.9\n",
            "narwhals==1.39.0\n",
            "natsort==8.4.0\n",
            "nbclassic==1.3.1\n",
            "nbclient==0.10.2\n",
            "nbconvert==7.16.6\n",
            "nbformat==5.10.4\n",
            "ndindex==1.9.2\n",
            "nest-asyncio==1.6.0\n",
            "networkx==3.4.2\n",
            "nibabel==5.3.2\n",
            "nltk==3.9.1\n",
            "notebook==6.5.7\n",
            "notebook_shim==0.2.4\n",
            "numba==0.60.0\n",
            "numba-cuda==0.2.0\n",
            "numexpr==2.10.2\n",
            "numpy==2.0.2\n",
            "nvidia-cublas-cu12==12.1.3.1\n",
            "nvidia-cuda-cupti-cu12==12.1.105\n",
            "nvidia-cuda-nvcc-cu12==12.5.82\n",
            "nvidia-cuda-nvrtc-cu12==12.1.105\n",
            "nvidia-cuda-runtime-cu12==12.1.105\n",
            "nvidia-cudnn-cu12==8.9.2.26\n",
            "nvidia-cufft-cu12==11.0.2.54\n",
            "nvidia-curand-cu12==10.3.2.106\n",
            "nvidia-cusolver-cu12==11.4.5.107\n",
            "nvidia-cusparse-cu12==12.1.0.106\n",
            "nvidia-cusparselt-cu12==0.6.2\n",
            "nvidia-ml-py==12.575.51\n",
            "nvidia-nccl-cu12==2.20.5\n",
            "nvidia-nvcomp-cu12==4.2.0.11\n",
            "nvidia-nvjitlink-cu12==12.5.82\n",
            "nvidia-nvtx-cu12==12.1.105\n",
            "nvtx==0.2.11\n",
            "nx-cugraph-cu12 @ https://pypi.nvidia.com/nx-cugraph-cu12/nx_cugraph_cu12-25.2.0-py3-none-any.whl\n",
            "oauth2client==4.1.3\n",
            "oauthlib==3.2.2\n",
            "omegaconf==2.3.0\n",
            "openai==1.78.1\n",
            "opencv-contrib-python==4.11.0.86\n",
            "opencv-python==4.11.0.86\n",
            "opencv-python-headless==4.11.0.86\n",
            "openpyxl==3.1.5\n",
            "opt_einsum==3.4.0\n",
            "optax==0.2.4\n",
            "optree==0.15.0\n",
            "orbax-checkpoint==0.11.13\n",
            "orjson==3.10.18\n",
            "osqp==1.0.4\n",
            "packaging==24.2\n",
            "pandas==2.2.2\n",
            "pandas-datareader==0.10.0\n",
            "pandas-gbq==0.28.1\n",
            "pandas-stubs==2.2.2.240909\n",
            "pandocfilters==1.5.1\n",
            "panel==1.6.3\n",
            "param==2.2.0\n",
            "parso==0.8.4\n",
            "parsy==2.1\n",
            "partd==1.4.2\n",
            "pathlib==1.0.1\n",
            "patsy==1.0.1\n",
            "peewee==3.18.1\n",
            "peft==0.15.2\n",
            "pexpect==4.9.0\n",
            "pickleshare==0.7.5\n",
            "pillow==11.2.1\n",
            "platformdirs==4.3.8\n",
            "plotly==5.24.1\n",
            "plotnine==0.14.5\n",
            "pluggy==1.5.0\n",
            "ply==3.11\n",
            "polars==1.21.0\n",
            "pooch==1.8.2\n",
            "portpicker==1.5.2\n",
            "preshed==3.0.9\n",
            "prettytable==3.16.0\n",
            "proglog==0.1.12\n",
            "progressbar2==4.5.0\n",
            "prometheus_client==0.21.1\n",
            "promise==2.3\n",
            "prompt_toolkit==3.0.51\n",
            "propcache==0.3.1\n",
            "prophet==1.1.6\n",
            "proto-plus==1.26.1\n",
            "protobuf==5.29.4\n",
            "psutil==5.9.5\n",
            "psycopg2==2.9.10\n",
            "ptyprocess==0.7.0\n",
            "py-cpuinfo==9.0.0\n",
            "py4j==0.10.9.7\n",
            "pyarrow==18.1.0\n",
            "pyasn1==0.6.1\n",
            "pyasn1_modules==0.4.2\n",
            "pycairo==1.28.0\n",
            "pycocotools==2.0.8\n",
            "pycparser==2.22\n",
            "pycryptodomex==3.22.0\n",
            "pydantic==2.11.4\n",
            "pydantic_core==2.33.2\n",
            "pydata-google-auth==1.9.1\n",
            "pydot==3.0.4\n",
            "pydotplus==2.0.2\n",
            "PyDrive==1.3.1\n",
            "PyDrive2==1.21.3\n",
            "pyerfa==2.0.1.5\n",
            "pygame==2.6.1\n",
            "pygit2==1.18.0\n",
            "Pygments==2.19.1\n",
            "PyGObject==3.42.0\n",
            "PyJWT==2.10.1\n",
            "pylibcudf-cu12 @ https://pypi.nvidia.com/pylibcudf-cu12/pylibcudf_cu12-25.2.1-cp311-cp311-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl\n",
            "pylibcugraph-cu12==25.2.0\n",
            "pylibraft-cu12==25.2.0\n",
            "pymc==5.22.0\n",
            "pymystem3==0.2.0\n",
            "pynndescent==0.5.13\n",
            "pynvjitlink-cu12==0.6.0\n",
            "pynvml==12.0.0\n",
            "pyogrio==0.11.0\n",
            "pyomo==6.9.2\n",
            "PyOpenGL==3.1.9\n",
            "pyOpenSSL==24.2.1\n",
            "pyparsing==3.2.3\n",
            "pyperclip==1.9.0\n",
            "pyproj==3.7.1\n",
            "pyproject_hooks==1.2.0\n",
            "pyshp==2.3.1\n",
            "PySocks==1.7.1\n",
            "pyspark==3.5.1\n",
            "pytensor==2.30.3\n",
            "pytest==8.3.5\n",
            "python-apt==0.0.0\n",
            "python-box==7.3.2\n",
            "python-dateutil==2.9.0.post0\n",
            "python-louvain==0.16\n",
            "python-slugify==8.0.4\n",
            "python-snappy==0.7.3\n",
            "python-utils==3.9.1\n",
            "pytz==2025.2\n",
            "pyviz_comms==3.0.4\n",
            "PyWavelets==1.8.0\n",
            "PyYAML==6.0.2\n",
            "pyzmq==24.0.1\n",
            "raft-dask-cu12==25.2.0\n",
            "rapids-dask-dependency==25.2.0\n",
            "ratelim==0.1.6\n",
            "referencing==0.36.2\n",
            "regex==2024.11.6\n",
            "requests==2.32.3\n",
            "requests-oauthlib==2.0.0\n",
            "requests-toolbelt==1.0.0\n",
            "requirements-parser==0.9.0\n",
            "rich==13.9.4\n",
            "rmm-cu12==25.2.0\n",
            "roman-numerals-py==3.1.0\n",
            "rpds-py==0.24.0\n",
            "rpy2==3.5.17\n",
            "rsa==4.9.1\n",
            "safetensors==0.5.3\n",
            "scikit-image==0.25.2\n",
            "scikit-learn==1.6.1\n",
            "scipy==1.15.3\n",
            "scooby==0.10.1\n",
            "scs==3.2.7.post2\n",
            "seaborn==0.13.2\n",
            "SecretStorage==3.3.3\n",
            "Send2Trash==1.8.3\n",
            "sentence-transformers==4.1.0\n",
            "sentencepiece==0.2.0\n",
            "sentry-sdk==2.28.0\n",
            "setproctitle==1.3.6\n",
            "shap==0.47.2\n",
            "shapely==2.1.0\n",
            "shellingham==1.5.4\n",
            "simple-parsing==0.1.7\n",
            "simplejson==3.20.1\n",
            "simsimd==6.2.1\n",
            "six==1.17.0\n",
            "sklearn-compat==0.1.3\n",
            "sklearn-pandas==2.2.0\n",
            "slicer==0.0.8\n",
            "smart-open==7.1.0\n",
            "smmap==5.0.2\n",
            "sniffio==1.3.1\n",
            "snowballstemmer==3.0.1\n",
            "sortedcontainers==2.4.0\n",
            "soundfile==0.13.1\n",
            "soupsieve==2.7\n",
            "soxr==0.5.0.post1\n",
            "spacy==3.8.5\n",
            "spacy-legacy==3.0.12\n",
            "spacy-loggers==1.0.5\n",
            "spanner-graph-notebook==1.1.6\n",
            "Sphinx==8.2.3\n",
            "sphinxcontrib-applehelp==2.0.0\n",
            "sphinxcontrib-devhelp==2.0.0\n",
            "sphinxcontrib-htmlhelp==2.1.0\n",
            "sphinxcontrib-jsmath==1.0.1\n",
            "sphinxcontrib-qthelp==2.0.0\n",
            "sphinxcontrib-serializinghtml==2.0.0\n",
            "SQLAlchemy==2.0.40\n",
            "sqlglot==25.20.2\n",
            "sqlparse==0.5.3\n",
            "srsly==2.5.1\n",
            "stanio==0.5.1\n",
            "statsmodels==0.14.4\n",
            "stringzilla==3.12.5\n",
            "stumpy==1.13.0\n",
            "sympy==1.13.1\n",
            "tables==3.10.2\n",
            "tabulate==0.9.0\n",
            "tbb==2022.1.0\n",
            "tblib==3.1.0\n",
            "tcmlib==1.3.0\n",
            "tenacity==9.1.2\n",
            "tensorboard==2.18.0\n",
            "tensorboard-data-server==0.7.2\n",
            "tensorflow==2.18.0\n",
            "tensorflow-datasets==4.9.8\n",
            "tensorflow-hub==0.16.1\n",
            "tensorflow-io-gcs-filesystem==0.37.1\n",
            "tensorflow-metadata==1.17.1\n",
            "tensorflow-probability==0.25.0\n",
            "tensorflow-text==2.18.1\n",
            "tensorflow_decision_forests==1.11.0\n",
            "tensorstore==0.1.74\n",
            "termcolor==3.1.0\n",
            "terminado==0.18.1\n",
            "text-unidecode==1.3\n",
            "textblob==0.19.0\n",
            "tf-slim==1.1.0\n",
            "tf_keras==2.18.0\n",
            "thinc==8.3.6\n",
            "threadpoolctl==3.6.0\n",
            "tifffile==2025.5.10\n",
            "tiktoken==0.9.0\n",
            "timm==1.0.15\n",
            "tinycss2==1.4.0\n",
            "tokenizers==0.21.1\n",
            "toml==0.10.2\n",
            "toolz==0.12.1\n",
            "torch==2.3.0\n",
            "torchao==0.10.0\n",
            "torchaudio @ https://download.pytorch.org/whl/cu124/torchaudio-2.6.0%2Bcu124-cp311-cp311-linux_x86_64.whl\n",
            "torchdata==0.11.0\n",
            "torchsummary==1.5.1\n",
            "torchtext==0.18.0\n",
            "torchtune==0.6.1\n",
            "torchvision @ https://download.pytorch.org/whl/cu124/torchvision-0.21.0%2Bcu124-cp311-cp311-linux_x86_64.whl\n",
            "tornado==6.4.2\n",
            "tqdm==4.67.1\n",
            "traitlets==5.7.1\n",
            "traittypes==0.2.1\n",
            "transformers==4.51.3\n",
            "treelite==4.4.1\n",
            "treescope==0.1.9\n",
            "triton==2.3.0\n",
            "tsfresh==0.21.0\n",
            "tweepy==4.15.0\n",
            "typeguard==4.4.2\n",
            "typer==0.15.3\n",
            "types-pytz==2025.2.0.20250326\n",
            "types-setuptools==80.4.0.20250511\n",
            "typing-inspection==0.4.0\n",
            "typing_extensions==4.13.2\n",
            "tzdata==2025.2\n",
            "tzlocal==5.3.1\n",
            "uc-micro-py==1.0.3\n",
            "ucx-py-cu12==0.42.0\n",
            "ucxx-cu12==0.42.0\n",
            "umap-learn==0.5.7\n",
            "umf==0.10.0\n",
            "uritemplate==4.1.1\n",
            "urllib3==2.4.0\n",
            "vega-datasets==0.9.0\n",
            "wadllib==1.3.6\n",
            "wandb==0.19.11\n",
            "wasabi==1.1.3\n",
            "wcwidth==0.2.13\n",
            "weasel==0.4.1\n",
            "webcolors==24.11.1\n",
            "webencodings==0.5.1\n",
            "websocket-client==1.8.0\n",
            "websockets==15.0.1\n",
            "Werkzeug==3.1.3\n",
            "widgetsnbextension==3.6.10\n",
            "wordcloud==1.9.4\n",
            "wrapt==1.17.2\n",
            "wurlitzer==3.1.1\n",
            "xarray==2025.3.1\n",
            "xarray-einstats==0.8.0\n",
            "xgboost==2.1.4\n",
            "xlrd==2.0.1\n",
            "xxhash==3.5.0\n",
            "xyzservices==2025.4.0\n",
            "yarl==1.20.0\n",
            "ydf==0.11.0\n",
            "yellowbrick==1.5\n",
            "yfinance==0.2.61\n",
            "zict==3.0.0\n",
            "zipp==3.21.0\n",
            "zstandard==0.23.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "jXnagBYmi_YI"
      },
      "outputs": [],
      "source": [
        "SEED = 42 #to reproduce the traning\n",
        "\n",
        "random.seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "torch.manual_seed(SEED)\n",
        "torch.cuda.manual_seed(SEED)\n",
        "torch.backends.cudnn.deterministic = True"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torchtext\n",
        "dir(torchtext)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7-QhBRQ0JEwO",
        "outputId": "b0ebe882-6ec4-42cf-e3bd-559c0ed04f25"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['_CACHE_DIR',\n",
              " '_TEXT_BUCKET',\n",
              " '_TORCHTEXT_DEPRECATION_MSG',\n",
              " '_WARN',\n",
              " '__all__',\n",
              " '__builtins__',\n",
              " '__cached__',\n",
              " '__doc__',\n",
              " '__file__',\n",
              " '__loader__',\n",
              " '__name__',\n",
              " '__package__',\n",
              " '__path__',\n",
              " '__spec__',\n",
              " '__version__',\n",
              " '_extension',\n",
              " '_get_torch_home',\n",
              " '_internal',\n",
              " '_torchtext',\n",
              " 'disable_torchtext_deprecation_warning',\n",
              " 'git_version',\n",
              " 'os',\n",
              " 'version']"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "gjVU2ynri_YJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d92bcb2c-f23c-4621-9d5b-ea796c2f44d5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torchtext/data/__init__.py:4: UserWarning: \n",
            "/!\\ IMPORTANT WARNING ABOUT TORCHTEXT STATUS /!\\ \n",
            "Torchtext is deprecated and the last released version will be 0.18 (this one). You can silence this warning by calling the following at the beginnign of your scripts: `import torchtext; torchtext.disable_torchtext_deprecation_warning()`\n",
            "  warnings.warn(torchtext._TORCHTEXT_DEPRECATION_MSG)\n",
            "/usr/local/lib/python3.11/dist-packages/torchtext/vocab/__init__.py:4: UserWarning: \n",
            "/!\\ IMPORTANT WARNING ABOUT TORCHTEXT STATUS /!\\ \n",
            "Torchtext is deprecated and the last released version will be 0.18 (this one). You can silence this warning by calling the following at the beginnign of your scripts: `import torchtext; torchtext.disable_torchtext_deprecation_warning()`\n",
            "  warnings.warn(torchtext._TORCHTEXT_DEPRECATION_MSG)\n",
            "/usr/local/lib/python3.11/dist-packages/torchtext/utils.py:4: UserWarning: \n",
            "/!\\ IMPORTANT WARNING ABOUT TORCHTEXT STATUS /!\\ \n",
            "Torchtext is deprecated and the last released version will be 0.18 (this one). You can silence this warning by calling the following at the beginnign of your scripts: `import torchtext; torchtext.disable_torchtext_deprecation_warning()`\n",
            "  warnings.warn(torchtext._TORCHTEXT_DEPRECATION_MSG)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['T_destination', '__annotations__', '__call__', '__class__', '__contains__', '__delattr__', '__dict__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattr__', '__getattribute__', '__getitem__', '__getstate__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__jit_unused_properties__', '__le__', '__len__', '__lt__', '__module__', '__ne__', '__new__', '__prepare_scriptable__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__setstate__', '__sizeof__', '__str__', '__subclasshook__', '__weakref__', '_apply', '_backward_hooks', '_backward_pre_hooks', '_buffers', '_call_impl', '_compiled_call_impl', '_forward_hooks', '_forward_hooks_always_called', '_forward_hooks_with_kwargs', '_forward_pre_hooks', '_forward_pre_hooks_with_kwargs', '_get_backward_hooks', '_get_backward_pre_hooks', '_get_name', '_is_full_backward_hook', '_load_from_state_dict', '_load_state_dict_post_hooks', '_load_state_dict_pre_hooks', '_maybe_warn_non_full_backward_hook', '_modules', '_named_members', '_non_persistent_buffers_set', '_parameters', '_register_load_state_dict_pre_hook', '_register_state_dict_hook', '_replicate_for_data_parallel', '_save_to_state_dict', '_slow_forward', '_state_dict_hooks', '_state_dict_pre_hooks', '_version', '_wrapped_call_impl', 'add_module', 'append_token', 'apply', 'bfloat16', 'buffers', 'call_super_init', 'children', 'compile', 'cpu', 'cuda', 'double', 'dump_patches', 'eval', 'extra_repr', 'float', 'forward', 'get_buffer', 'get_default_index', 'get_extra_state', 'get_itos', 'get_parameter', 'get_stoi', 'get_submodule', 'half', 'insert_token', 'ipu', 'is_jitable', 'load_state_dict', 'lookup_indices', 'lookup_token', 'lookup_tokens', 'modules', 'named_buffers', 'named_children', 'named_modules', 'named_parameters', 'parameters', 'register_backward_hook', 'register_buffer', 'register_forward_hook', 'register_forward_pre_hook', 'register_full_backward_hook', 'register_full_backward_pre_hook', 'register_load_state_dict_post_hook', 'register_module', 'register_parameter', 'register_state_dict_pre_hook', 'requires_grad_', 'set_default_index', 'set_extra_state', 'share_memory', 'state_dict', 'to', 'to_empty', 'train', 'training', 'type', 'vocab', 'xpu', 'zero_grad']\n"
          ]
        }
      ],
      "source": [
        "import torchtext\n",
        "import torch\n",
        "from torchtext.data.utils import get_tokenizer\n",
        "from collections import Counter\n",
        "from torchtext.vocab import vocab\n",
        "#from torchtext.utils import download_from_url, extract_archive\n",
        "import io\n",
        "\n",
        "#0=en 1=de\n",
        "# soure and target data\n",
        "#NOTE: USE clean bpe data!\n",
        "\n",
        "#for this task I used the clean bpe files (train 500k, test 500, dev 500)\n",
        "#sorting the path to the files en-de\n",
        "train_filepaths = ['train.en-de.clean.bpe.en', 'train.en-de.clean.bpe.de']\n",
        "val_filepaths = ['dev.en-de.clean.bpe.en', 'dev.en-de.clean.bpe.de']\n",
        "test_filepaths = ['test.en-de.clean.bpe.en', 'test.en-de.clean.bpe.de']\n",
        "\n",
        "#TODO use clean bpe tokenized data!!!\n",
        "\n",
        "#de_tokenizer = get_tokenizer('moses', language='de') for cases without bpe data\n",
        "#en_tokenizer = get_tokenizer('moses', language='en')\n",
        "\n",
        "de_tokenizer = None #None as there are tokenized data\n",
        "en_tokenizer = None\n",
        "\n",
        "def build_vocab(filepath, tokenizer=None):\n",
        "  counter = Counter()\n",
        "  with io.open(filepath, encoding=\"utf8\") as f: #go to a file\n",
        "    for string_ in f: #for each line in a file\n",
        "      #counter.update(tokenizer(string_))\n",
        "      counter.update(string_.split()) #split each line by space, i.e. creating tokens. Counter counts the tokens to create a database of the vocab\n",
        "  return vocab(counter, specials=['<unk>', '<pad>', '<bos>', '<eos>']) #vocav from torchtext containing the tokens and their counts, as well as specioal ones\n",
        "\n",
        "#Vocab\n",
        "en_vocab = build_vocab(train_filepaths[0], en_tokenizer) #create a vocab\n",
        "de_vocab = build_vocab(train_filepaths[1], de_tokenizer)\n",
        "\n",
        "print(dir(en_vocab))\n",
        "en_vocab.set_default_index(en_vocab['<unk>']) #set <unk> as a default token\n",
        "de_vocab.set_default_index(de_vocab['<unk>'])\n",
        "\n",
        "def data_process(filepaths):\n",
        "  raw_en_iter = iter(io.open(filepaths[0], encoding=\"utf8\"))\n",
        "  raw_de_iter = iter(io.open(filepaths[1], encoding=\"utf8\"))\n",
        "  data = []\n",
        "  for (raw_en, raw_de) in zip(raw_en_iter, raw_de_iter): #for each sentence in the source and target\n",
        "    en_tensor_ = torch.tensor([en_vocab[token] for token in raw_en.split()], #en_tokenizer(raw_en) #transforms tokens into tensors\n",
        "                            dtype=torch.long)\n",
        "    de_tensor_ = torch.tensor([de_vocab[token] for token in raw_de.split()], #de_tokenizer(raw_de)\n",
        "                            dtype=torch.long)\n",
        "    data.append((en_tensor_, de_tensor_)) #append to a list\n",
        "  return data\n",
        "\n",
        "#pre-process\n",
        "train_data = data_process(train_filepaths)\n",
        "val_data = data_process(val_filepaths)\n",
        "test_data = data_process(test_filepaths)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "Wo6Mz24Itw7B"
      },
      "outputs": [],
      "source": [
        "#NOTE: if you are low on credits or testing only use a piece of the data e.g. 20K segments\n",
        "train_data = train_data[:1000]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(train_data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IAgj_76lFM7j",
        "outputId": "a3f15b25-9ddf-49bc-f87e-e707a9c79183"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1000"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(val_data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gDJRIU9iFN4C",
        "outputId": "84bdb7d4-3800-4c61-8a4a-6d79e400ed58"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "466"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G8FHO7cfuHz_",
        "outputId": "e70c7eb9-dadd-4608-956b-f6bebcf1f908"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "467"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ],
      "source": [
        "len(test_data)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(en_vocab)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b7NfZiOZFR67",
        "outputId": "41f3f335-7b29-440c-a13d-ba8165c4422e"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "36926"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(de_vocab)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fQnYGdL1gM-w",
        "outputId": "cab7ac28-de29-43b9-b672-04d5f9c1f0fa"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "42161"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RyZRMk_Yi_YJ"
      },
      "source": [
        "Define the device."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XNS-Dmk0i_YJ",
        "outputId": "8066f83b-a6df-499f-a6e3-eed089b9736b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda\n"
          ]
        }
      ],
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MWUIbF0Wi_YK"
      },
      "source": [
        "Create the iterators."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "tCHlMlZYi_YK"
      },
      "outputs": [],
      "source": [
        "BATCH_SIZE = 10\n",
        "PAD_IDX = de_vocab['<pad>'] #find the indecies of the special tokens\n",
        "BOS_IDX = de_vocab['<bos>']\n",
        "EOS_IDX = de_vocab['<eos>']\n",
        "\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "def generate_batch(data_batch):\n",
        "    en_batch, de_batch = [], []\n",
        "    for (en_item, de_item) in data_batch: #each sentences in a batch\n",
        "        de_batch.append(torch.cat([torch.tensor([BOS_IDX]), de_item, torch.tensor([EOS_IDX])], dim=0)) #add a source sentence from the beginning (BOS) till the end (EOS)\n",
        "        en_batch.append(torch.cat([torch.tensor([BOS_IDX]), en_item, torch.tensor([EOS_IDX])], dim=0))\n",
        "    de_batch = pad_sequence(de_batch, padding_value=PAD_IDX, batch_first=True) #add padding to sentences if they are of different langth\n",
        "    en_batch = pad_sequence(en_batch, padding_value=PAD_IDX, batch_first=True)\n",
        "    return en_batch, de_batch\n",
        "\n",
        "train_iter = DataLoader(train_data, batch_size=BATCH_SIZE,\n",
        "                        shuffle=True, collate_fn=generate_batch) #shuffle samples after each epoch\n",
        "valid_iter = DataLoader(val_data, batch_size=BATCH_SIZE,\n",
        "                        shuffle=False, collate_fn=generate_batch)\n",
        "test_iter = DataLoader(test_data, batch_size=BATCH_SIZE,\n",
        "                       shuffle=False, collate_fn=generate_batch)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GjnN1Aj0i_YK"
      },
      "source": [
        "## Building the Seq2Seq Model\n",
        "\n",
        "### Encoder\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "zf4mEJnhi_YK"
      },
      "outputs": [],
      "source": [
        "class Encoder(nn.Module):\n",
        "    def __init__(self, input_dim, emb_dim, enc_hid_dim, dec_hid_dim, dropout):\n",
        "        super().__init__()\n",
        "\n",
        "        self.embedding = nn.Embedding(input_dim, emb_dim) #size of vocab (50k from clean bpe data), embedding dimensionality (256 from below)\n",
        "\n",
        "        #[YOUR CODE] GRU(embeding size, encoder hidden size) NOTE: bidirectional batch_first\n",
        "        # parameters for GRU in Pytorch\n",
        "        # torch.nn.GRU(input_size, hidden_size, num_layers=1, bias=True, batch_first=False, dropout=0.0, bidirectional=False, device=None, dtype=None)\n",
        "        self.rnn = nn.GRU(input_size=emb_dim, hidden_size=enc_hid_dim, batch_first=True, bidirectional=True)\n",
        "\n",
        "        #[YOUR CODE] linear(encoder hidden size * 2, decoder hidden size)\n",
        "        # times 2 as we have a bidirectional model\n",
        "        self.fc = nn.Linear(enc_hid_dim * 2, dec_hid_dim)\n",
        "\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, src):\n",
        "\n",
        "        #[B=8, S= longest sentence]\n",
        "        embedded = self.embedding(src) #embed the source\n",
        "\n",
        "        #[B, S, E] print(embedded.size())\n",
        "        # the matrix grow by the additional dimension of the embedding size (256)\n",
        "\n",
        "        embedded = self.dropout(embedded) #regularize the embeddings\n",
        "\n",
        "        #[B, S, E]\n",
        "        #[YOUR CODE] rrn(embeddings)\n",
        "        outputs, hidden = self.rnn(embedded)\n",
        "\n",
        "        #[B, S, H*2]\n",
        "\n",
        "        #h[n layers * num directions, batch size, hid dim]\n",
        "\n",
        "        #[forward_1, backward_1, forward_2, backward_2, ...]\n",
        "\n",
        "        #[-2, :, : ] last state forward RNN\n",
        "        #[-1, :, : ] last state backward RNN\n",
        "        print('hid', hidden.size())\n",
        "\n",
        "        #[YOUR CODE] last state forward RNN\n",
        "        h1 = hidden[-2, :, : ]\n",
        "\n",
        "        #[YOUR CODE] last state backward RNN\n",
        "        h2 = hidden[-1, :, : ]\n",
        "\n",
        "        #https://pytorch.org/docs/main/generated/torch.cat.html\n",
        "\n",
        "        #[YOUR CODE] concatenate h1 amd h2 on seq dim\n",
        "        h_cat = torch.cat([h1, h2], dim=1)\n",
        "\n",
        "        #[YOUR CODE] tanh(linear(hidden_cat))\n",
        "        hidden = torch.tanh(self.fc(h_cat))\n",
        "\n",
        "        #[B, S, H*2]\n",
        "\n",
        "        return outputs, hidden # outputs = vector for each sentence, hidden = concatenated vector for forward and backward"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Attention\n",
        "\n",
        "## Luong Attention\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "5Av3fvEwEAXM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Formula: score(target hidden state, each source hidden stare) = target hidden state transposed * W * eachsource hidden state)"
      ],
      "metadata": {
        "id": "WTNnkMtTubSg"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "kP4jL01Vi_YL"
      },
      "outputs": [],
      "source": [
        "class LuongAttention(nn.Module):\n",
        "    def __init__(self, enc_hid_dim, dec_hid_dim):\n",
        "        super().__init__()\n",
        "\n",
        "        self.attn = nn.Linear((enc_hid_dim * 2) + dec_hid_dim, dec_hid_dim)\n",
        "        self.v = nn.Linear(dec_hid_dim, 1, bias = False)\n",
        "\n",
        "    def forward(self, hidden, encoder_outputs): #keys, query  hidden = target\n",
        "\n",
        "        #[batch size, dec hid dim]\n",
        "        #[src len, batch size, enc hid dim * 2]\n",
        "\n",
        "        batch_size = encoder_outputs.shape[0] #to see the size\n",
        "        src_len = encoder_outputs.shape[1]\n",
        "\n",
        "        #x times decoder hidden state for the size of the src_len\n",
        "        hidden = hidden.unsqueeze(1).repeat(1, src_len, 1) #repatn the hidden state over source\n",
        "\n",
        "        #[batch size, src len, dec hid dim]\n",
        "\n",
        "        scores = torch.tanh(self.attn(torch.cat((hidden, encoder_outputs), dim = 2))) #concateneted in the embedding dimension\n",
        "        # attn = linear layer\n",
        "        # tanh = non-linear\n",
        "\n",
        "        #[batch size, src len, dec hid dim]\n",
        "\n",
        "        attention = self.v(scores).squeeze(2) # v is W in the formula\n",
        "\n",
        "        #[batch size, src len]\n",
        "\n",
        "        return F.softmax(attention, dim=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Formula: score(target hidden state, each source hidden stare) = Va transposed * tanh(W1 * target hidden state + W2 * each source hidden state)"
      ],
      "metadata": {
        "id": "ST2kpwDJw50m"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "sFSa__e8_ZQB"
      },
      "outputs": [],
      "source": [
        "class BahdanauAttention(nn.Module):\n",
        "    def __init__(self, enc_hid_dim, dec_hid_dim):\n",
        "        super(BahdanauAttention, self).__init__()\n",
        "        self.Wa = nn.Linear(dec_hid_dim, dec_hid_dim, bias=False)\n",
        "        self.Ua = nn.Linear(enc_hid_dim * 2, dec_hid_dim, bias=False)\n",
        "        self.Va = nn.Linear(dec_hid_dim, 1, bias=False)\n",
        "\n",
        "    def forward(self, hidden, encoder_outputs): #keys, query\n",
        "        #[YOUR CODE]\n",
        "        batch_size = encoder_outputs.shape(0)\n",
        "        src_len = encoder_outputs.shape(1)\n",
        "\n",
        "        #x times decoder hidden state for src_len\n",
        "        #[YOUR CODE]\n",
        "        hidden = hidden.unsqueeze(1).repeat(1, src_len, 1)  # pytorch - Returns a new tensor with a dimension of size one inserted at the specified position.\n",
        "\n",
        "        \"\"\"\n",
        "        >>> x = torch.tensor([1, 2, 3, 4])\n",
        "        >>> torch.unsqueeze(x, 0)\n",
        "        tensor([[ 1,  2,  3,  4]])\n",
        "        >>> torch.unsqueeze(x, 1)\n",
        "        tensor([[ 1],\n",
        "                [ 2],\n",
        "                [ 3],\n",
        "                [ 4]])\n",
        "        \"\"\"\n",
        "\n",
        "        #[YOUR CODE] Va(tanh(Wa(hidden) + Ua(encoder outputs)))\n",
        "        scores = self.Va(torch.tanh(self.Wa(hidden) + self.Ua(encoder_outputs)))\n",
        "\n",
        "        scores = scores.squeeze(2) #Returns a tensor with all specified dimensions of input of size 1 removed.\n",
        "\n",
        "        \"\"\"\n",
        "        For example, if input is of shape: (A×1×B×C×1×D) then the input.squeeze() will be of shape: (A×B×C×D).\n",
        "        When dim is given, a squeeze operation is done only in the given dimension(s). If input is of shape:\n",
        "        (A×1×B), squeeze(input, 0) leaves the tensor unchanged, but squeeze(input, 1) will squeeze the tensor to the shape (A×B).\n",
        "        \"\"\"\n",
        "\n",
        "        #[YOUR CODE] softmax(scores, dim seq)\n",
        "        weights =  torch.softmax(scores, dim=1)\n",
        "\n",
        "        return weights"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PWvboaMki_YL"
      },
      "source": [
        "### Decoder\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "t_J_RZPbi_YL"
      },
      "outputs": [],
      "source": [
        "class Decoder(nn.Module):\n",
        "    def __init__(self, output_dim, emb_dim, enc_hid_dim, dec_hid_dim, dropout, attention):\n",
        "        super().__init__()\n",
        "\n",
        "        self.output_dim = output_dim\n",
        "\n",
        "        self.attention = attention\n",
        "\n",
        "        self.embedding = nn.Embedding(output_dim, emb_dim)\n",
        "\n",
        "        self.rnn = nn.GRU((enc_hid_dim * 2) + emb_dim, dec_hid_dim, batch_first=True)\n",
        "\n",
        "        self.fc_out = nn.Linear((enc_hid_dim * 2) + dec_hid_dim + emb_dim, output_dim)\n",
        "\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "        #attention\n",
        "        self.attn = nn.Linear((enc_hid_dim * 2) + dec_hid_dim, dec_hid_dim)\n",
        "        self.v = nn.Linear(dec_hid_dim, 1, bias = False)\n",
        "\n",
        "    def forward(self, input, hidden, encoder_outputs):\n",
        "\n",
        "        #[batch size]\n",
        "        #[batch size, dec hid dim]\n",
        "        #[src len, batch size, enc hid dim * 2]\n",
        "\n",
        "        input = input.unsqueeze(0)\n",
        "\n",
        "        #[1, batch size]\n",
        "\n",
        "        embedded = self.dropout(self.embedding(input))\n",
        "\n",
        "        #[1, batch size, emb dim]\n",
        "\n",
        "        a = self.attention(hidden, encoder_outputs)\n",
        "\n",
        "        #[batch size, src len]\n",
        "\n",
        "        a = a.unsqueeze(1)\n",
        "\n",
        "        #[batch size, 1, src len]\n",
        "\n",
        "        #[batch size, src len, enc hid dim * 2]\n",
        "\n",
        "        weighted = torch.bmm(a, encoder_outputs)\n",
        "\n",
        "        #[batch size, 1, enc hid dim * 2]\n",
        "\n",
        "        weighted = weighted.permute(1, 0, 2)\n",
        "\n",
        "        #[1, batch size, enc hid dim * 2]\n",
        "\n",
        "        rnn_input = torch.cat((embedded, weighted), dim = 2)\n",
        "\n",
        "        #[1, batch size, (enc hid dim * 2) + emb dim]\n",
        "        #[B, 1, (enc hid dim * 2) + emb dim]\n",
        "\n",
        "        rnn_input = rnn_input.permute(1, 0, 2)\n",
        "        hidden = hidden.unsqueeze(0)\n",
        "\n",
        "        output, hidden = self.rnn(rnn_input, hidden)\n",
        "\n",
        "        #[seq len, batch size, dec hid dim * n directions]\n",
        "        #[n layers * n directions, batch size, dec hid dim]\n",
        "\n",
        "        #[1, batch size, dec hid dim]\n",
        "        #[1, batch size, dec hid dim]\n",
        "\n",
        "        embedded = embedded.squeeze(0)\n",
        "        output = output.squeeze(1)\n",
        "        weighted = weighted.squeeze(0)\n",
        "\n",
        "        prediction = self.fc_out(torch.cat((output, weighted, embedded), dim = 1))\n",
        "\n",
        "        #[batch size, output dim]\n",
        "\n",
        "        return prediction, hidden.squeeze(0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d33lfUX9i_YL"
      },
      "source": [
        "### Seq2Seq\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "GwoMHRFxi_YL"
      },
      "outputs": [],
      "source": [
        "class Seq2Seq(nn.Module):\n",
        "    def __init__(self, encoder, decoder, device):\n",
        "        super().__init__()\n",
        "\n",
        "        self.encoder = encoder\n",
        "        self.decoder = decoder\n",
        "        self.device = device\n",
        "\n",
        "\n",
        "    def forward(self, src, trg, teacher_forcing_ratio = 0.5):\n",
        "\n",
        "        #[src len, batch size]\n",
        "        #[trg len, batch size]\n",
        "        #teacher_forcing_ratio is probability to use teacher forcing\n",
        "        # 0.75 teacher forcing 75% of the time\n",
        "\n",
        "        batch_size = src.shape[0]\n",
        "        trg_len = trg.shape[1]\n",
        "        trg_vocab_size = self.decoder.output_dim\n",
        "\n",
        "\n",
        "        outputs = torch.zeros(batch_size, trg_len, trg_vocab_size).to(self.device)\n",
        "\n",
        "        #encoder_outputs is all hidden states of the input sequence\n",
        "        #hidden is the final forward and backward hidden states, passed through a linear layer\n",
        "        encoder_outputs, hidden = self.encoder(src)\n",
        "\n",
        "        #first input to the decoder is the <sos> tokens\n",
        "        input = trg[:,0]\n",
        "        # unroll RNN\n",
        "        for t in range(1, trg_len):\n",
        "\n",
        "            #insert input token embedding, previous hidden state and all encoder hidden states\n",
        "\n",
        "            output, hidden = self.decoder(input, hidden, encoder_outputs)\n",
        "\n",
        "            #predictions\n",
        "            outputs[:, t] = output\n",
        "\n",
        "            #teacher forcing\n",
        "            teacher_force = random.random() < teacher_forcing_ratio\n",
        "\n",
        "            #greedy search\n",
        "            top1 = output.argmax(1)\n",
        "\n",
        "            #if teacher forcing, use gold token as next input\n",
        "            #if not, use predicted token\n",
        "            input = trg[:, t] if teacher_force else top1\n",
        "\n",
        "        return outputs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e06yvLvei_YL"
      },
      "source": [
        "## Training the Seq2Seq Model\n",
        "\n",
        "Firstly, I have been training first with tranining data size = 1000, batch size =10, num of epoch = 3 and Luong attention\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "5jC9nxari_YM"
      },
      "outputs": [],
      "source": [
        "INPUT_DIM = len(en_vocab)\n",
        "OUTPUT_DIM = len(de_vocab)\n",
        "ENC_EMB_DIM = 256\n",
        "DEC_EMB_DIM = 256\n",
        "ENC_HID_DIM = 512\n",
        "DEC_HID_DIM = 512\n",
        "ENC_DROPOUT = 0.5\n",
        "DEC_DROPOUT = 0.2\n",
        "\n",
        "attn = LuongAttention(ENC_HID_DIM, DEC_HID_DIM)\n",
        "#[YOUR CODE] Bahdanau attn\n",
        "attn_bahdanau = BahdanauAttention(ENC_HID_DIM, DEC_HID_DIM)\n",
        "enc = Encoder(INPUT_DIM, ENC_EMB_DIM, ENC_HID_DIM, DEC_HID_DIM, ENC_DROPOUT)\n",
        "dec = Decoder(OUTPUT_DIM, DEC_EMB_DIM, ENC_HID_DIM, DEC_HID_DIM, DEC_DROPOUT, attn)\n",
        "\n",
        "model = Seq2Seq(enc, dec, device).to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DGLEjaJu2NjY",
        "outputId": "b1d65f08-d86d-426f-fc94-cf3f53991fa6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "36926\n",
            "42161\n"
          ]
        }
      ],
      "source": [
        "print(len(en_vocab)) #BPE size 16k approx\n",
        "print(len(de_vocab))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rUD45Ys5i_YM",
        "outputId": "b6012aba-08c6-4c16-cdbb-aee1d700117d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Seq2Seq(\n",
              "  (encoder): Encoder(\n",
              "    (embedding): Embedding(36926, 256)\n",
              "    (rnn): GRU(256, 512, batch_first=True, bidirectional=True)\n",
              "    (fc): Linear(in_features=1024, out_features=512, bias=True)\n",
              "    (dropout): Dropout(p=0.5, inplace=False)\n",
              "  )\n",
              "  (decoder): Decoder(\n",
              "    (attention): LuongAttention(\n",
              "      (attn): Linear(in_features=1536, out_features=512, bias=True)\n",
              "      (v): Linear(in_features=512, out_features=1, bias=False)\n",
              "    )\n",
              "    (embedding): Embedding(42161, 256)\n",
              "    (rnn): GRU(1280, 512, batch_first=True)\n",
              "    (fc_out): Linear(in_features=1792, out_features=42161, bias=True)\n",
              "    (dropout): Dropout(p=0.2, inplace=False)\n",
              "    (attn): Linear(in_features=1536, out_features=512, bias=True)\n",
              "    (v): Linear(in_features=512, out_features=1, bias=False)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ],
      "source": [
        "def init_weights(m):\n",
        "    for name, param in m.named_parameters():\n",
        "        if 'weight' in name:\n",
        "            nn.init.normal_(param.data, mean=0, std=0.01)\n",
        "        else:\n",
        "            nn.init.constant_(param.data, 0)\n",
        "\n",
        "model.apply(init_weights)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bmY0twjqi_YM",
        "outputId": "8e506601-24c3-4c1a-e25e-51cb0e544c14"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The model has 103,061,681 trainable parameters\n"
          ]
        }
      ],
      "source": [
        "def count_parameters(model):\n",
        "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "\n",
        "print(f'The model has {count_parameters(model):,} trainable parameters')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W6M5jMx9i_YM"
      },
      "source": [
        "We create an optimizer."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "GkFpvqEii_YM"
      },
      "outputs": [],
      "source": [
        "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
        "#[YOUR CODE] Adam lr 1e-3"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "POJ6uKGei_YM"
      },
      "source": [
        "We initialize the loss function."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "McD_2eGsi_YM"
      },
      "outputs": [],
      "source": [
        "TRG_PAD_IDX = de_vocab['<pad>'] #TODO\n",
        "#https://pytorch.org/docs/stable/generated/torch.nn.CrossEntropyLoss.html\n",
        "criterion = nn.CrossEntropyLoss(ignore_index=TRG_PAD_IDX)\n",
        "\n",
        "#[YOUR CODE] loss add ignore_index idx\n",
        "#parameters\n",
        "#torch.nn.CrossEntropyLoss(weight=None, size_average=None, ignore_index=-100, reduce=None, reduction='mean', label_smoothing=0.0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DBn2uizpi_YM",
        "outputId": "ecaef1ba-dcfa-492c-f531-b87c44ad10a9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1\n"
          ]
        }
      ],
      "source": [
        "print(TRG_PAD_IDX)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "ZWBC8pDAi_YN"
      },
      "outputs": [],
      "source": [
        "def train(model, iterator, optimizer, criterion, clip):\n",
        "\n",
        "    #[YOUR CODE] set model train model.train()\n",
        "    model.train()\n",
        "\n",
        "    epoch_loss = 0\n",
        "\n",
        "    for (src, trg) in tqdm(iterator):\n",
        "\n",
        "        #[YOUR CODE] to gpu\n",
        "        src = src.to(device)\n",
        "        trg = trg.to(device)\n",
        "\n",
        "        #[YOUR CODE] optimizer zero grad\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        #[YOUR CODE] model()\n",
        "        output = model(src, trg)\n",
        "\n",
        "        #[trg len, batch size]\n",
        "        #[trg len, batch size, output dim]\n",
        "\n",
        "        output = output.permute(1, 0, 2)\n",
        "\n",
        "        output_dim = output.shape[-1]\n",
        "        trg = trg.permute(1, 0)\n",
        "\n",
        "        output = output[1:].reshape(-1, output_dim)\n",
        "        trg = trg[1:].reshape(-1)\n",
        "\n",
        "        #[(trg len - 1) * batch size]\n",
        "        #[(trg len - 1) * batch size, output dim]\n",
        "\n",
        "        #[YOUR CODE] criterion()\n",
        "        loss = criterion(output, trg)\n",
        "\n",
        "        #[YOUR CODE] loss backward\n",
        "        loss.backward()\n",
        "\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
        "\n",
        "        #[YOUR CODE] optimizer step\n",
        "        optimizer.step()\n",
        "\n",
        "        epoch_loss += loss.item()\n",
        "\n",
        "    return epoch_loss / len(iterator)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "lJGxS6mFi_YN"
      },
      "outputs": [],
      "source": [
        "def evaluate(model, iterator, criterion):\n",
        "\n",
        "    #[YOUR CODE] set model test/eval  model.eval()\n",
        "    model.eval()\n",
        "\n",
        "    epoch_loss = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "\n",
        "        for (src, trg) in iterator:\n",
        "            #[YOUR CODE] to device\n",
        "            src = src.to(device)\n",
        "            trg = trg.to(device)\n",
        "\n",
        "            #[YOUR CODE] model() turn off teacher forcing 0\n",
        "            output = model(src, trg, 0)\n",
        "\n",
        "            #trg = [trg len, batch size]\n",
        "            #output = [trg len, batch size, output dim]\n",
        "\n",
        "            output = output.permute(1, 0, 2)\n",
        "            output_dim = output.shape[-1]\n",
        "            trg = trg.permute(1, 0)\n",
        "            output = output[1:].reshape(-1, output_dim)\n",
        "            trg = trg[1:].reshape(-1)\n",
        "\n",
        "            #trg = [(trg len - 1) * batch size]\n",
        "            #output = [(trg len - 1) * batch size, output dim]\n",
        "\n",
        "            #[YOUR CODE] criterion()\n",
        "            loss = criterion(output, trg)\n",
        "\n",
        "            epoch_loss += loss.item()\n",
        "\n",
        "    return epoch_loss / len(iterator)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AFGhRjIMi_YN",
        "outputId": "ed5dbc6a-6e7f-458d-dbb2-b41004c29940"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/100 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hid torch.Size([2, 10, 512])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  1%|          | 1/100 [00:00<01:15,  1.32it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hid torch.Size([2, 10, 512])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  2%|▏         | 2/100 [00:01<00:53,  1.83it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hid torch.Size([2, 10, 512])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  3%|▎         | 3/100 [00:02<01:16,  1.27it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hid torch.Size([2, 10, 512])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  4%|▍         | 4/100 [00:03<01:20,  1.19it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hid torch.Size([2, 10, 512])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  5%|▌         | 5/100 [00:03<01:13,  1.29it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hid torch.Size([2, 10, 512])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  6%|▌         | 6/100 [00:04<01:04,  1.45it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hid torch.Size([2, 10, 512])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  7%|▋         | 7/100 [00:04<00:59,  1.58it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hid torch.Size([2, 10, 512])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  8%|▊         | 8/100 [00:05<00:55,  1.65it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hid torch.Size([2, 10, 512])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  9%|▉         | 9/100 [00:05<00:52,  1.73it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hid torch.Size([2, 10, 512])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 10%|█         | 10/100 [00:06<00:49,  1.82it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hid torch.Size([2, 10, 512])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 11%|█         | 11/100 [00:06<00:46,  1.91it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hid torch.Size([2, 10, 512])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 12%|█▏        | 12/100 [00:08<01:02,  1.40it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hid torch.Size([2, 10, 512])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 13%|█▎        | 13/100 [00:08<01:03,  1.37it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hid torch.Size([2, 10, 512])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 14%|█▍        | 14/100 [00:09<01:02,  1.37it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hid torch.Size([2, 10, 512])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 15%|█▌        | 15/100 [00:10<00:55,  1.52it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hid torch.Size([2, 10, 512])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 16%|█▌        | 16/100 [00:10<00:52,  1.60it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hid torch.Size([2, 10, 512])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 17%|█▋        | 17/100 [00:11<00:51,  1.61it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hid torch.Size([2, 10, 512])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 18%|█▊        | 18/100 [00:11<00:50,  1.63it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hid torch.Size([2, 10, 512])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 19%|█▉        | 19/100 [00:12<00:47,  1.69it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hid torch.Size([2, 10, 512])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 20%|██        | 20/100 [00:13<00:57,  1.39it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hid torch.Size([2, 10, 512])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 21%|██        | 21/100 [00:13<00:49,  1.60it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hid torch.Size([2, 10, 512])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 22%|██▏       | 22/100 [00:14<00:59,  1.31it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hid torch.Size([2, 10, 512])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 23%|██▎       | 23/100 [00:15<00:59,  1.29it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hid torch.Size([2, 10, 512])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 24%|██▍       | 24/100 [00:16<01:00,  1.25it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hid torch.Size([2, 10, 512])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 25%|██▌       | 25/100 [00:17<00:59,  1.27it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hid torch.Size([2, 10, 512])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 26%|██▌       | 26/100 [00:17<00:53,  1.38it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hid torch.Size([2, 10, 512])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 27%|██▋       | 27/100 [00:18<00:55,  1.32it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hid torch.Size([2, 10, 512])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 28%|██▊       | 28/100 [00:19<00:47,  1.51it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hid torch.Size([2, 10, 512])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 29%|██▉       | 29/100 [00:19<00:48,  1.48it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hid torch.Size([2, 10, 512])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 30%|███       | 30/100 [00:20<00:45,  1.54it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hid torch.Size([2, 10, 512])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 31%|███       | 31/100 [00:21<00:45,  1.52it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hid torch.Size([2, 10, 512])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 32%|███▏      | 32/100 [00:22<01:00,  1.13it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hid torch.Size([2, 10, 512])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 33%|███▎      | 33/100 [00:23<00:59,  1.12it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hid torch.Size([2, 10, 512])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 34%|███▍      | 34/100 [00:24<00:57,  1.15it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hid torch.Size([2, 10, 512])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 35%|███▌      | 35/100 [00:24<00:50,  1.30it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hid torch.Size([2, 10, 512])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 36%|███▌      | 36/100 [00:26<00:59,  1.07it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hid torch.Size([2, 10, 512])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 37%|███▋      | 37/100 [00:26<00:55,  1.14it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hid torch.Size([2, 10, 512])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 38%|███▊      | 38/100 [00:27<00:51,  1.21it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hid torch.Size([2, 10, 512])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 39%|███▉      | 39/100 [00:28<00:45,  1.34it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hid torch.Size([2, 10, 512])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 40%|████      | 40/100 [00:28<00:38,  1.55it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hid torch.Size([2, 10, 512])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 41%|████      | 41/100 [00:28<00:34,  1.69it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hid torch.Size([2, 10, 512])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 42%|████▏     | 42/100 [00:29<00:33,  1.75it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hid torch.Size([2, 10, 512])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 43%|████▎     | 43/100 [00:30<00:33,  1.71it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hid torch.Size([2, 10, 512])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 44%|████▍     | 44/100 [00:30<00:33,  1.70it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hid torch.Size([2, 10, 512])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 45%|████▌     | 45/100 [00:31<00:30,  1.79it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hid torch.Size([2, 10, 512])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 46%|████▌     | 46/100 [00:31<00:28,  1.86it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hid torch.Size([2, 10, 512])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 47%|████▋     | 47/100 [00:32<00:29,  1.82it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hid torch.Size([2, 10, 512])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 48%|████▊     | 48/100 [00:32<00:31,  1.64it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hid torch.Size([2, 10, 512])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 49%|████▉     | 49/100 [00:33<00:29,  1.76it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hid torch.Size([2, 10, 512])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 50%|█████     | 50/100 [00:33<00:27,  1.81it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hid torch.Size([2, 10, 512])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 51%|█████     | 51/100 [00:34<00:27,  1.78it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hid torch.Size([2, 10, 512])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 52%|█████▏    | 52/100 [00:35<00:29,  1.64it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hid torch.Size([2, 10, 512])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 53%|█████▎    | 53/100 [00:36<00:33,  1.40it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hid torch.Size([2, 10, 512])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 54%|█████▍    | 54/100 [00:36<00:28,  1.59it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hid torch.Size([2, 10, 512])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 55%|█████▌    | 55/100 [00:37<00:29,  1.53it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hid torch.Size([2, 10, 512])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 56%|█████▌    | 56/100 [00:38<00:28,  1.54it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hid torch.Size([2, 10, 512])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 57%|█████▋    | 57/100 [00:38<00:25,  1.72it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hid torch.Size([2, 10, 512])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 58%|█████▊    | 58/100 [00:39<00:30,  1.37it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hid torch.Size([2, 10, 512])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 59%|█████▉    | 59/100 [00:39<00:26,  1.55it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hid torch.Size([2, 10, 512])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 60%|██████    | 60/100 [00:40<00:27,  1.47it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hid torch.Size([2, 10, 512])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 61%|██████    | 61/100 [00:41<00:29,  1.32it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hid torch.Size([2, 10, 512])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 62%|██████▏   | 62/100 [00:43<00:35,  1.06it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hid torch.Size([2, 10, 512])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 63%|██████▎   | 63/100 [00:43<00:31,  1.17it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hid torch.Size([2, 10, 512])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 64%|██████▍   | 64/100 [00:44<00:27,  1.29it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hid torch.Size([2, 10, 512])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 65%|██████▌   | 65/100 [00:44<00:24,  1.41it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hid torch.Size([2, 10, 512])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 66%|██████▌   | 66/100 [00:45<00:23,  1.45it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hid torch.Size([2, 10, 512])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 67%|██████▋   | 67/100 [00:46<00:21,  1.51it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hid torch.Size([2, 10, 512])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 68%|██████▊   | 68/100 [00:47<00:25,  1.27it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hid torch.Size([2, 10, 512])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 69%|██████▉   | 69/100 [00:48<00:25,  1.21it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hid torch.Size([2, 10, 512])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 70%|███████   | 70/100 [00:48<00:23,  1.26it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hid torch.Size([2, 10, 512])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 71%|███████   | 71/100 [00:49<00:21,  1.33it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hid torch.Size([2, 10, 512])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 72%|███████▏  | 72/100 [00:50<00:25,  1.11it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hid torch.Size([2, 10, 512])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 73%|███████▎  | 73/100 [00:51<00:24,  1.09it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hid torch.Size([2, 10, 512])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 74%|███████▍  | 74/100 [00:52<00:19,  1.32it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hid torch.Size([2, 10, 512])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 75%|███████▌  | 75/100 [00:52<00:16,  1.48it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hid torch.Size([2, 10, 512])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 76%|███████▌  | 76/100 [00:53<00:15,  1.53it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hid torch.Size([2, 10, 512])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 77%|███████▋  | 77/100 [00:53<00:13,  1.69it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hid torch.Size([2, 10, 512])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 78%|███████▊  | 78/100 [00:54<00:12,  1.74it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hid torch.Size([2, 10, 512])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 79%|███████▉  | 79/100 [00:54<00:14,  1.50it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hid torch.Size([2, 10, 512])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 80%|████████  | 80/100 [00:56<00:16,  1.24it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hid torch.Size([2, 10, 512])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 81%|████████  | 81/100 [00:56<00:12,  1.50it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hid torch.Size([2, 10, 512])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 82%|████████▏ | 82/100 [00:57<00:11,  1.57it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hid torch.Size([2, 10, 512])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 83%|████████▎ | 83/100 [00:57<00:10,  1.59it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hid torch.Size([2, 10, 512])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 84%|████████▍ | 84/100 [00:58<00:10,  1.48it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hid torch.Size([2, 10, 512])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 85%|████████▌ | 85/100 [00:59<00:10,  1.39it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hid torch.Size([2, 10, 512])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 86%|████████▌ | 86/100 [00:59<00:09,  1.54it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hid torch.Size([2, 10, 512])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 87%|████████▋ | 87/100 [01:00<00:08,  1.49it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hid torch.Size([2, 10, 512])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 88%|████████▊ | 88/100 [01:00<00:07,  1.59it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hid torch.Size([2, 10, 512])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 89%|████████▉ | 89/100 [01:01<00:06,  1.70it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hid torch.Size([2, 10, 512])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 90%|█████████ | 90/100 [01:02<00:07,  1.39it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hid torch.Size([2, 10, 512])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 91%|█████████ | 91/100 [01:03<00:06,  1.46it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hid torch.Size([2, 10, 512])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 92%|█████████▏| 92/100 [01:03<00:05,  1.37it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hid torch.Size([2, 10, 512])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 93%|█████████▎| 93/100 [01:04<00:04,  1.46it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hid torch.Size([2, 10, 512])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 94%|█████████▍| 94/100 [01:05<00:03,  1.53it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hid torch.Size([2, 10, 512])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 95%|█████████▌| 95/100 [01:05<00:03,  1.61it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hid torch.Size([2, 10, 512])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 96%|█████████▌| 96/100 [01:06<00:02,  1.66it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hid torch.Size([2, 10, 512])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 97%|█████████▋| 97/100 [01:07<00:02,  1.48it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hid torch.Size([2, 10, 512])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 98%|█████████▊| 98/100 [01:07<00:01,  1.65it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hid torch.Size([2, 10, 512])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 99%|█████████▉| 99/100 [01:08<00:00,  1.28it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hid torch.Size([2, 10, 512])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 100/100 [01:09<00:00,  1.45it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hid torch.Size([2, 10, 512])\n",
            "hid torch.Size([2, 10, 512])\n",
            "hid torch.Size([2, 10, 512])\n",
            "hid torch.Size([2, 10, 512])\n",
            "hid torch.Size([2, 10, 512])\n",
            "hid torch.Size([2, 10, 512])\n",
            "hid torch.Size([2, 10, 512])\n",
            "hid torch.Size([2, 10, 512])\n",
            "hid torch.Size([2, 10, 512])\n",
            "hid torch.Size([2, 10, 512])\n",
            "hid torch.Size([2, 10, 512])\n",
            "hid torch.Size([2, 10, 512])\n",
            "hid torch.Size([2, 10, 512])\n",
            "hid torch.Size([2, 10, 512])\n",
            "hid torch.Size([2, 10, 512])\n",
            "hid torch.Size([2, 10, 512])\n",
            "hid torch.Size([2, 10, 512])\n",
            "hid torch.Size([2, 10, 512])\n",
            "hid torch.Size([2, 10, 512])\n",
            "hid torch.Size([2, 10, 512])\n",
            "hid torch.Size([2, 10, 512])\n",
            "hid torch.Size([2, 10, 512])\n",
            "hid torch.Size([2, 10, 512])\n",
            "hid torch.Size([2, 10, 512])\n",
            "hid torch.Size([2, 10, 512])\n",
            "hid torch.Size([2, 10, 512])\n",
            "hid torch.Size([2, 10, 512])\n",
            "hid torch.Size([2, 10, 512])\n",
            "hid torch.Size([2, 10, 512])\n",
            "hid torch.Size([2, 10, 512])\n",
            "hid torch.Size([2, 10, 512])\n",
            "hid torch.Size([2, 10, 512])\n",
            "hid torch.Size([2, 10, 512])\n",
            "hid torch.Size([2, 10, 512])\n",
            "hid torch.Size([2, 10, 512])\n",
            "hid torch.Size([2, 10, 512])\n",
            "hid torch.Size([2, 10, 512])\n",
            "hid torch.Size([2, 10, 512])\n",
            "hid torch.Size([2, 10, 512])\n",
            "hid torch.Size([2, 10, 512])\n",
            "hid torch.Size([2, 10, 512])\n",
            "hid torch.Size([2, 10, 512])\n",
            "hid torch.Size([2, 10, 512])\n",
            "hid torch.Size([2, 10, 512])\n",
            "hid torch.Size([2, 10, 512])\n",
            "hid torch.Size([2, 10, 512])\n",
            "hid torch.Size([2, 6, 512])\n",
            "Epoch: 01\n",
            "\tTrain Loss: 10.688\tTrain PPL: 43816.560\n",
            "\t Validation Loss: 10.685\tValidation PPL: 43682.609\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/100 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hid torch.Size([2, 10, 512])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  1%|          | 1/100 [00:00<01:08,  1.44it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hid torch.Size([2, 10, 512])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  2%|▏         | 2/100 [00:01<01:18,  1.25it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hid torch.Size([2, 10, 512])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  3%|▎         | 3/100 [00:02<01:07,  1.45it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hid torch.Size([2, 10, 512])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  4%|▍         | 4/100 [00:03<01:16,  1.25it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hid torch.Size([2, 10, 512])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  5%|▌         | 5/100 [00:03<01:10,  1.34it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hid torch.Size([2, 10, 512])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  6%|▌         | 6/100 [00:04<01:14,  1.26it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hid torch.Size([2, 10, 512])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  7%|▋         | 7/100 [00:05<01:11,  1.30it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hid torch.Size([2, 10, 512])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  8%|▊         | 8/100 [00:06<01:14,  1.24it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hid torch.Size([2, 10, 512])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  9%|▉         | 9/100 [00:06<01:06,  1.38it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hid torch.Size([2, 10, 512])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 10%|█         | 10/100 [00:07<01:01,  1.46it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hid torch.Size([2, 10, 512])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 11%|█         | 11/100 [00:07<00:58,  1.51it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hid torch.Size([2, 10, 512])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 12%|█▏        | 12/100 [00:08<00:56,  1.55it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hid torch.Size([2, 10, 512])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 13%|█▎        | 13/100 [00:09<00:53,  1.63it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hid torch.Size([2, 10, 512])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 14%|█▍        | 14/100 [00:09<00:48,  1.76it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hid torch.Size([2, 10, 512])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 15%|█▌        | 15/100 [00:10<01:03,  1.34it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hid torch.Size([2, 10, 512])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 16%|█▌        | 16/100 [00:11<01:10,  1.19it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hid torch.Size([2, 10, 512])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 17%|█▋        | 17/100 [00:12<01:01,  1.35it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hid torch.Size([2, 10, 512])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 18%|█▊        | 18/100 [00:12<00:56,  1.44it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hid torch.Size([2, 10, 512])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 19%|█▉        | 19/100 [00:13<00:50,  1.62it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hid torch.Size([2, 10, 512])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 20%|██        | 20/100 [00:13<00:45,  1.77it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hid torch.Size([2, 10, 512])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 21%|██        | 21/100 [00:14<00:43,  1.81it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hid torch.Size([2, 10, 512])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 22%|██▏       | 22/100 [00:14<00:37,  2.06it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hid torch.Size([2, 10, 512])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 23%|██▎       | 23/100 [00:15<00:35,  2.14it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hid torch.Size([2, 10, 512])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 24%|██▍       | 24/100 [00:16<00:54,  1.39it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hid torch.Size([2, 10, 512])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 25%|██▌       | 25/100 [00:16<00:46,  1.60it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hid torch.Size([2, 10, 512])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 26%|██▌       | 26/100 [00:17<00:44,  1.68it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hid torch.Size([2, 10, 512])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 27%|██▋       | 27/100 [00:17<00:42,  1.72it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hid torch.Size([2, 10, 512])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 28%|██▊       | 28/100 [00:18<00:41,  1.73it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hid torch.Size([2, 10, 512])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 29%|██▉       | 29/100 [00:18<00:40,  1.77it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hid torch.Size([2, 10, 512])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 30%|███       | 30/100 [00:19<00:39,  1.79it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hid torch.Size([2, 10, 512])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 31%|███       | 31/100 [00:20<00:37,  1.84it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hid torch.Size([2, 10, 512])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 32%|███▏      | 32/100 [00:21<00:47,  1.43it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hid torch.Size([2, 10, 512])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 33%|███▎      | 33/100 [00:22<00:55,  1.20it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hid torch.Size([2, 10, 512])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 34%|███▍      | 34/100 [00:22<00:46,  1.43it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hid torch.Size([2, 10, 512])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 35%|███▌      | 35/100 [00:23<00:56,  1.14it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hid torch.Size([2, 10, 512])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 36%|███▌      | 36/100 [00:24<00:45,  1.40it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hid torch.Size([2, 10, 512])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 37%|███▋      | 37/100 [00:25<00:45,  1.37it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hid torch.Size([2, 10, 512])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 38%|███▊      | 38/100 [00:25<00:41,  1.50it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hid torch.Size([2, 10, 512])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 39%|███▉      | 39/100 [00:26<00:39,  1.54it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hid torch.Size([2, 10, 512])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 40%|████      | 40/100 [00:26<00:36,  1.65it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hid torch.Size([2, 10, 512])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 41%|████      | 41/100 [00:27<00:35,  1.67it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hid torch.Size([2, 10, 512])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 42%|████▏     | 42/100 [00:27<00:35,  1.62it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hid torch.Size([2, 10, 512])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 43%|████▎     | 43/100 [00:28<00:34,  1.65it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hid torch.Size([2, 10, 512])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 44%|████▍     | 44/100 [00:28<00:29,  1.90it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hid torch.Size([2, 10, 512])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 45%|████▌     | 45/100 [00:29<00:28,  1.90it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hid torch.Size([2, 10, 512])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 46%|████▌     | 46/100 [00:30<00:32,  1.68it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hid torch.Size([2, 10, 512])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 47%|████▋     | 47/100 [00:30<00:31,  1.68it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hid torch.Size([2, 10, 512])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 48%|████▊     | 48/100 [00:31<00:29,  1.75it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hid torch.Size([2, 10, 512])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 49%|████▉     | 49/100 [00:31<00:29,  1.75it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hid torch.Size([2, 10, 512])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 50%|█████     | 50/100 [00:32<00:27,  1.84it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hid torch.Size([2, 10, 512])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 51%|█████     | 51/100 [00:32<00:24,  1.99it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hid torch.Size([2, 10, 512])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 52%|█████▏    | 52/100 [00:33<00:23,  2.00it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hid torch.Size([2, 10, 512])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 53%|█████▎    | 53/100 [00:33<00:24,  1.91it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hid torch.Size([2, 10, 512])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 54%|█████▍    | 54/100 [00:34<00:23,  1.93it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hid torch.Size([2, 10, 512])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 55%|█████▌    | 55/100 [00:35<00:27,  1.65it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hid torch.Size([2, 10, 512])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 56%|█████▌    | 56/100 [00:36<00:36,  1.21it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hid torch.Size([2, 10, 512])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 57%|█████▋    | 57/100 [00:37<00:37,  1.15it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hid torch.Size([2, 10, 512])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 58%|█████▊    | 58/100 [00:37<00:32,  1.30it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hid torch.Size([2, 10, 512])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 59%|█████▉    | 59/100 [00:38<00:28,  1.44it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hid torch.Size([2, 10, 512])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 60%|██████    | 60/100 [00:39<00:26,  1.49it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hid torch.Size([2, 10, 512])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 61%|██████    | 61/100 [00:39<00:27,  1.42it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hid torch.Size([2, 10, 512])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 62%|██████▏   | 62/100 [00:40<00:25,  1.51it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hid torch.Size([2, 10, 512])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 63%|██████▎   | 63/100 [00:40<00:22,  1.67it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hid torch.Size([2, 10, 512])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 64%|██████▍   | 64/100 [00:41<00:26,  1.37it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hid torch.Size([2, 10, 512])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 65%|██████▌   | 65/100 [00:42<00:26,  1.30it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hid torch.Size([2, 10, 512])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 66%|██████▌   | 66/100 [00:43<00:29,  1.17it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hid torch.Size([2, 10, 512])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 67%|██████▋   | 67/100 [00:44<00:27,  1.21it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hid torch.Size([2, 10, 512])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 68%|██████▊   | 68/100 [00:45<00:26,  1.22it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hid torch.Size([2, 10, 512])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 69%|██████▉   | 69/100 [00:46<00:25,  1.20it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hid torch.Size([2, 10, 512])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 70%|███████   | 70/100 [00:46<00:21,  1.37it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hid torch.Size([2, 10, 512])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 71%|███████   | 71/100 [00:47<00:21,  1.35it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hid torch.Size([2, 10, 512])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 72%|███████▏  | 72/100 [00:47<00:18,  1.51it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hid torch.Size([2, 10, 512])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 73%|███████▎  | 73/100 [00:48<00:19,  1.37it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hid torch.Size([2, 10, 512])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 74%|███████▍  | 74/100 [00:49<00:18,  1.37it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hid torch.Size([2, 10, 512])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 75%|███████▌  | 75/100 [00:50<00:16,  1.48it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hid torch.Size([2, 10, 512])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 76%|███████▌  | 76/100 [00:51<00:18,  1.27it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hid torch.Size([2, 10, 512])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 77%|███████▋  | 77/100 [00:51<00:18,  1.24it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hid torch.Size([2, 10, 512])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 78%|███████▊  | 78/100 [00:52<00:14,  1.48it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hid torch.Size([2, 10, 512])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 79%|███████▉  | 79/100 [00:52<00:12,  1.63it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hid torch.Size([2, 10, 512])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 80%|████████  | 80/100 [00:53<00:10,  1.91it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hid torch.Size([2, 10, 512])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 81%|████████  | 81/100 [00:53<00:11,  1.69it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hid torch.Size([2, 10, 512])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 82%|████████▏ | 82/100 [00:54<00:10,  1.78it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hid torch.Size([2, 10, 512])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 83%|████████▎ | 83/100 [00:54<00:09,  1.81it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hid torch.Size([2, 10, 512])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 84%|████████▍ | 84/100 [00:55<00:09,  1.65it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hid torch.Size([2, 10, 512])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 85%|████████▌ | 85/100 [00:56<00:08,  1.67it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hid torch.Size([2, 10, 512])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 86%|████████▌ | 86/100 [00:56<00:09,  1.56it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hid torch.Size([2, 10, 512])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 87%|████████▋ | 87/100 [00:57<00:07,  1.64it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hid torch.Size([2, 10, 512])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 88%|████████▊ | 88/100 [00:57<00:06,  1.84it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hid torch.Size([2, 10, 512])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 89%|████████▉ | 89/100 [00:58<00:06,  1.69it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hid torch.Size([2, 10, 512])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 90%|█████████ | 90/100 [00:59<00:07,  1.32it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hid torch.Size([2, 10, 512])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 91%|█████████ | 91/100 [01:00<00:06,  1.33it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hid torch.Size([2, 10, 512])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 92%|█████████▏| 92/100 [01:01<00:07,  1.05it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hid torch.Size([2, 10, 512])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 93%|█████████▎| 93/100 [01:02<00:05,  1.30it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hid torch.Size([2, 10, 512])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 94%|█████████▍| 94/100 [01:02<00:04,  1.38it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hid torch.Size([2, 10, 512])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 95%|█████████▌| 95/100 [01:03<00:03,  1.59it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hid torch.Size([2, 10, 512])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 96%|█████████▌| 96/100 [01:03<00:02,  1.52it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hid torch.Size([2, 10, 512])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 97%|█████████▋| 97/100 [01:04<00:02,  1.50it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hid torch.Size([2, 10, 512])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 98%|█████████▊| 98/100 [01:05<00:01,  1.30it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hid torch.Size([2, 10, 512])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 99%|█████████▉| 99/100 [01:06<00:00,  1.40it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hid torch.Size([2, 10, 512])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 100/100 [01:06<00:00,  1.50it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hid torch.Size([2, 10, 512])\n",
            "hid torch.Size([2, 10, 512])\n",
            "hid torch.Size([2, 10, 512])\n",
            "hid torch.Size([2, 10, 512])\n",
            "hid torch.Size([2, 10, 512])\n",
            "hid torch.Size([2, 10, 512])\n",
            "hid torch.Size([2, 10, 512])\n",
            "hid torch.Size([2, 10, 512])\n",
            "hid torch.Size([2, 10, 512])\n",
            "hid torch.Size([2, 10, 512])\n",
            "hid torch.Size([2, 10, 512])\n",
            "hid torch.Size([2, 10, 512])\n",
            "hid torch.Size([2, 10, 512])\n",
            "hid torch.Size([2, 10, 512])\n",
            "hid torch.Size([2, 10, 512])\n",
            "hid torch.Size([2, 10, 512])\n",
            "hid torch.Size([2, 10, 512])\n",
            "hid torch.Size([2, 10, 512])\n",
            "hid torch.Size([2, 10, 512])\n",
            "hid torch.Size([2, 10, 512])\n",
            "hid torch.Size([2, 10, 512])\n",
            "hid torch.Size([2, 10, 512])\n",
            "hid torch.Size([2, 10, 512])\n",
            "hid torch.Size([2, 10, 512])\n",
            "hid torch.Size([2, 10, 512])\n",
            "hid torch.Size([2, 10, 512])\n",
            "hid torch.Size([2, 10, 512])\n",
            "hid torch.Size([2, 10, 512])\n",
            "hid torch.Size([2, 10, 512])\n",
            "hid torch.Size([2, 10, 512])\n",
            "hid torch.Size([2, 10, 512])\n",
            "hid torch.Size([2, 10, 512])\n",
            "hid torch.Size([2, 10, 512])\n",
            "hid torch.Size([2, 10, 512])\n",
            "hid torch.Size([2, 10, 512])\n",
            "hid torch.Size([2, 10, 512])\n",
            "hid torch.Size([2, 10, 512])\n",
            "hid torch.Size([2, 10, 512])\n",
            "hid torch.Size([2, 10, 512])\n",
            "hid torch.Size([2, 10, 512])\n",
            "hid torch.Size([2, 10, 512])\n",
            "hid torch.Size([2, 10, 512])\n",
            "hid torch.Size([2, 10, 512])\n",
            "hid torch.Size([2, 10, 512])\n",
            "hid torch.Size([2, 10, 512])\n",
            "hid torch.Size([2, 10, 512])\n",
            "hid torch.Size([2, 6, 512])\n",
            "Epoch: 02\n",
            "\tTrain Loss: 10.688\tTrain PPL: 43815.816\n",
            "\t Validation Loss: 10.685\tValidation PPL: 43682.609\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/100 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hid torch.Size([2, 10, 512])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  1%|          | 1/100 [00:01<01:57,  1.18s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hid torch.Size([2, 10, 512])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  2%|▏         | 2/100 [00:02<01:37,  1.00it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hid torch.Size([2, 10, 512])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  3%|▎         | 3/100 [00:02<01:25,  1.14it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hid torch.Size([2, 10, 512])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  4%|▍         | 4/100 [00:03<01:16,  1.26it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hid torch.Size([2, 10, 512])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  5%|▌         | 5/100 [00:04<01:23,  1.13it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hid torch.Size([2, 10, 512])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  6%|▌         | 6/100 [00:05<01:25,  1.10it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hid torch.Size([2, 10, 512])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  7%|▋         | 7/100 [00:05<01:12,  1.28it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hid torch.Size([2, 10, 512])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  8%|▊         | 8/100 [00:06<01:04,  1.43it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hid torch.Size([2, 10, 512])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  9%|▉         | 9/100 [00:06<00:57,  1.58it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hid torch.Size([2, 10, 512])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 10%|█         | 10/100 [00:07<00:53,  1.68it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hid torch.Size([2, 10, 512])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 11%|█         | 11/100 [00:08<01:12,  1.23it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hid torch.Size([2, 10, 512])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 12%|█▏        | 12/100 [00:09<01:01,  1.44it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hid torch.Size([2, 10, 512])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 13%|█▎        | 13/100 [00:09<01:00,  1.43it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hid torch.Size([2, 10, 512])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 14%|█▍        | 14/100 [00:10<01:02,  1.37it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hid torch.Size([2, 10, 512])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 15%|█▌        | 15/100 [00:11<00:59,  1.42it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hid torch.Size([2, 10, 512])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 16%|█▌        | 16/100 [00:11<00:55,  1.52it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hid torch.Size([2, 10, 512])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 17%|█▋        | 17/100 [00:12<00:56,  1.48it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hid torch.Size([2, 10, 512])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 18%|█▊        | 18/100 [00:13<00:53,  1.54it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hid torch.Size([2, 10, 512])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 19%|█▉        | 19/100 [00:13<00:48,  1.65it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hid torch.Size([2, 10, 512])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 20%|██        | 20/100 [00:14<00:55,  1.44it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hid torch.Size([2, 10, 512])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 21%|██        | 21/100 [00:15<00:51,  1.53it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hid torch.Size([2, 10, 512])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 22%|██▏       | 22/100 [00:15<00:49,  1.57it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hid torch.Size([2, 10, 512])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 23%|██▎       | 23/100 [00:16<00:44,  1.75it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hid torch.Size([2, 10, 512])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 24%|██▍       | 24/100 [00:17<00:54,  1.39it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hid torch.Size([2, 10, 512])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 25%|██▌       | 25/100 [00:17<00:47,  1.60it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hid torch.Size([2, 10, 512])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 26%|██▌       | 26/100 [00:18<00:41,  1.77it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hid torch.Size([2, 10, 512])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 27%|██▋       | 27/100 [00:18<00:44,  1.63it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hid torch.Size([2, 10, 512])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 28%|██▊       | 28/100 [00:19<00:50,  1.44it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hid torch.Size([2, 10, 512])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 29%|██▉       | 29/100 [00:21<01:02,  1.13it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hid torch.Size([2, 10, 512])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 30%|███       | 30/100 [00:21<01:02,  1.13it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hid torch.Size([2, 10, 512])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 31%|███       | 31/100 [00:22<00:56,  1.22it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hid torch.Size([2, 10, 512])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 32%|███▏      | 32/100 [00:22<00:47,  1.44it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hid torch.Size([2, 10, 512])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 33%|███▎      | 33/100 [00:23<00:42,  1.59it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hid torch.Size([2, 10, 512])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 34%|███▍      | 34/100 [00:24<00:45,  1.44it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hid torch.Size([2, 10, 512])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 35%|███▌      | 35/100 [00:24<00:42,  1.54it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hid torch.Size([2, 10, 512])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 36%|███▌      | 36/100 [00:25<00:40,  1.59it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hid torch.Size([2, 10, 512])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 37%|███▋      | 37/100 [00:25<00:37,  1.67it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hid torch.Size([2, 10, 512])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 38%|███▊      | 38/100 [00:26<00:35,  1.75it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hid torch.Size([2, 10, 512])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 39%|███▉      | 39/100 [00:26<00:32,  1.89it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hid torch.Size([2, 10, 512])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 40%|████      | 40/100 [00:28<00:42,  1.41it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hid torch.Size([2, 10, 512])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 41%|████      | 41/100 [00:28<00:40,  1.45it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hid torch.Size([2, 10, 512])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 42%|████▏     | 42/100 [00:29<00:37,  1.53it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hid torch.Size([2, 10, 512])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 43%|████▎     | 43/100 [00:30<00:39,  1.43it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hid torch.Size([2, 10, 512])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 44%|████▍     | 44/100 [00:31<00:46,  1.19it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hid torch.Size([2, 10, 512])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 45%|████▌     | 45/100 [00:32<00:49,  1.11it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hid torch.Size([2, 10, 512])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 46%|████▌     | 46/100 [00:32<00:45,  1.20it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hid torch.Size([2, 10, 512])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 47%|████▋     | 47/100 [00:33<00:42,  1.25it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hid torch.Size([2, 10, 512])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 48%|████▊     | 48/100 [00:34<00:40,  1.27it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hid torch.Size([2, 10, 512])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 49%|████▉     | 49/100 [00:35<00:38,  1.31it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hid torch.Size([2, 10, 512])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 50%|█████     | 50/100 [00:35<00:33,  1.51it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hid torch.Size([2, 10, 512])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 51%|█████     | 51/100 [00:37<00:44,  1.11it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hid torch.Size([2, 10, 512])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 52%|█████▏    | 52/100 [00:37<00:38,  1.23it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hid torch.Size([2, 10, 512])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 53%|█████▎    | 53/100 [00:38<00:33,  1.42it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hid torch.Size([2, 10, 512])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 54%|█████▍    | 54/100 [00:38<00:31,  1.46it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hid torch.Size([2, 10, 512])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 55%|█████▌    | 55/100 [00:39<00:28,  1.58it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hid torch.Size([2, 10, 512])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 56%|█████▌    | 56/100 [00:39<00:29,  1.48it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hid torch.Size([2, 10, 512])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 57%|█████▋    | 57/100 [00:40<00:29,  1.48it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hid torch.Size([2, 10, 512])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 58%|█████▊    | 58/100 [00:41<00:30,  1.39it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hid torch.Size([2, 10, 512])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 59%|█████▉    | 59/100 [00:42<00:34,  1.17it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hid torch.Size([2, 10, 512])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 60%|██████    | 60/100 [00:43<00:30,  1.31it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hid torch.Size([2, 10, 512])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 61%|██████    | 61/100 [00:44<00:31,  1.25it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hid torch.Size([2, 10, 512])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 62%|██████▏   | 62/100 [00:44<00:27,  1.41it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hid torch.Size([2, 10, 512])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 63%|██████▎   | 63/100 [00:45<00:25,  1.47it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hid torch.Size([2, 10, 512])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 64%|██████▍   | 64/100 [00:45<00:23,  1.50it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hid torch.Size([2, 10, 512])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 65%|██████▌   | 65/100 [00:46<00:21,  1.64it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hid torch.Size([2, 10, 512])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 66%|██████▌   | 66/100 [00:47<00:21,  1.56it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hid torch.Size([2, 10, 512])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 67%|██████▋   | 67/100 [00:47<00:20,  1.62it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hid torch.Size([2, 10, 512])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 68%|██████▊   | 68/100 [00:48<00:21,  1.50it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hid torch.Size([2, 10, 512])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 69%|██████▉   | 69/100 [00:49<00:21,  1.44it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hid torch.Size([2, 10, 512])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 70%|███████   | 70/100 [00:49<00:18,  1.58it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hid torch.Size([2, 10, 512])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 71%|███████   | 71/100 [00:50<00:21,  1.37it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hid torch.Size([2, 10, 512])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 72%|███████▏  | 72/100 [00:51<00:21,  1.31it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hid torch.Size([2, 10, 512])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 73%|███████▎  | 73/100 [00:51<00:18,  1.49it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hid torch.Size([2, 10, 512])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 74%|███████▍  | 74/100 [00:52<00:18,  1.44it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hid torch.Size([2, 10, 512])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 75%|███████▌  | 75/100 [00:53<00:15,  1.58it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hid torch.Size([2, 10, 512])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 76%|███████▌  | 76/100 [00:53<00:13,  1.72it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hid torch.Size([2, 10, 512])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 77%|███████▋  | 77/100 [00:54<00:16,  1.37it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hid torch.Size([2, 10, 512])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 78%|███████▊  | 78/100 [00:55<00:14,  1.47it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hid torch.Size([2, 10, 512])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 79%|███████▉  | 79/100 [00:55<00:12,  1.65it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hid torch.Size([2, 10, 512])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 80%|████████  | 80/100 [00:56<00:11,  1.73it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hid torch.Size([2, 10, 512])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 81%|████████  | 81/100 [00:56<00:11,  1.60it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hid torch.Size([2, 10, 512])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 82%|████████▏ | 82/100 [00:57<00:13,  1.34it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hid torch.Size([2, 10, 512])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 83%|████████▎ | 83/100 [00:58<00:12,  1.40it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hid torch.Size([2, 10, 512])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 84%|████████▍ | 84/100 [00:59<00:10,  1.46it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hid torch.Size([2, 10, 512])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 85%|████████▌ | 85/100 [00:59<00:09,  1.60it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hid torch.Size([2, 10, 512])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 86%|████████▌ | 86/100 [01:00<00:08,  1.69it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hid torch.Size([2, 10, 512])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 87%|████████▋ | 87/100 [01:00<00:07,  1.65it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hid torch.Size([2, 10, 512])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 88%|████████▊ | 88/100 [01:01<00:07,  1.69it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hid torch.Size([2, 10, 512])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 89%|████████▉ | 89/100 [01:01<00:05,  1.86it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hid torch.Size([2, 10, 512])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 90%|█████████ | 90/100 [01:02<00:05,  1.78it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hid torch.Size([2, 10, 512])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 91%|█████████ | 91/100 [01:03<00:05,  1.63it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hid torch.Size([2, 10, 512])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 92%|█████████▏| 92/100 [01:03<00:04,  1.76it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hid torch.Size([2, 10, 512])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 93%|█████████▎| 93/100 [01:04<00:04,  1.55it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hid torch.Size([2, 10, 512])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 94%|█████████▍| 94/100 [01:04<00:03,  1.75it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hid torch.Size([2, 10, 512])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 95%|█████████▌| 95/100 [01:05<00:03,  1.52it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hid torch.Size([2, 10, 512])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 96%|█████████▌| 96/100 [01:06<00:02,  1.56it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hid torch.Size([2, 10, 512])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 97%|█████████▋| 97/100 [01:07<00:02,  1.46it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hid torch.Size([2, 10, 512])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 98%|█████████▊| 98/100 [01:07<00:01,  1.42it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hid torch.Size([2, 10, 512])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 99%|█████████▉| 99/100 [01:08<00:00,  1.36it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hid torch.Size([2, 10, 512])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 100/100 [01:09<00:00,  1.44it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hid torch.Size([2, 10, 512])\n",
            "hid torch.Size([2, 10, 512])\n",
            "hid torch.Size([2, 10, 512])\n",
            "hid torch.Size([2, 10, 512])\n",
            "hid torch.Size([2, 10, 512])\n",
            "hid torch.Size([2, 10, 512])\n",
            "hid torch.Size([2, 10, 512])\n",
            "hid torch.Size([2, 10, 512])\n",
            "hid torch.Size([2, 10, 512])\n",
            "hid torch.Size([2, 10, 512])\n",
            "hid torch.Size([2, 10, 512])\n",
            "hid torch.Size([2, 10, 512])\n",
            "hid torch.Size([2, 10, 512])\n",
            "hid torch.Size([2, 10, 512])\n",
            "hid torch.Size([2, 10, 512])\n",
            "hid torch.Size([2, 10, 512])\n",
            "hid torch.Size([2, 10, 512])\n",
            "hid torch.Size([2, 10, 512])\n",
            "hid torch.Size([2, 10, 512])\n",
            "hid torch.Size([2, 10, 512])\n",
            "hid torch.Size([2, 10, 512])\n",
            "hid torch.Size([2, 10, 512])\n",
            "hid torch.Size([2, 10, 512])\n",
            "hid torch.Size([2, 10, 512])\n",
            "hid torch.Size([2, 10, 512])\n",
            "hid torch.Size([2, 10, 512])\n",
            "hid torch.Size([2, 10, 512])\n",
            "hid torch.Size([2, 10, 512])\n",
            "hid torch.Size([2, 10, 512])\n",
            "hid torch.Size([2, 10, 512])\n",
            "hid torch.Size([2, 10, 512])\n",
            "hid torch.Size([2, 10, 512])\n",
            "hid torch.Size([2, 10, 512])\n",
            "hid torch.Size([2, 10, 512])\n",
            "hid torch.Size([2, 10, 512])\n",
            "hid torch.Size([2, 10, 512])\n",
            "hid torch.Size([2, 10, 512])\n",
            "hid torch.Size([2, 10, 512])\n",
            "hid torch.Size([2, 10, 512])\n",
            "hid torch.Size([2, 10, 512])\n",
            "hid torch.Size([2, 10, 512])\n",
            "hid torch.Size([2, 10, 512])\n",
            "hid torch.Size([2, 10, 512])\n",
            "hid torch.Size([2, 10, 512])\n",
            "hid torch.Size([2, 10, 512])\n",
            "hid torch.Size([2, 10, 512])\n",
            "hid torch.Size([2, 6, 512])\n",
            "Epoch: 03\n",
            "\tTrain Loss: 10.688\tTrain PPL: 43819.184\n",
            "\t Validation Loss: 10.685\tValidation PPL: 43682.609\n"
          ]
        }
      ],
      "source": [
        "N_EPOCHS = 3\n",
        "CLIP = 1\n",
        "\n",
        "epoch_info_list = []\n",
        "\n",
        "best_valid_loss = float('inf')\n",
        "\n",
        "for epoch in range(N_EPOCHS):\n",
        "\n",
        "    train_loss = train(model, train_iter, optimizer, criterion, CLIP)\n",
        "    valid_loss = evaluate(model, valid_iter, criterion)\n",
        "\n",
        "    if valid_loss < best_valid_loss:\n",
        "      #[YOUR CODE] extra add BLEU model selection\n",
        "      best_valid_loss = valid_loss\n",
        "      torch.save(model.state_dict(), 'model.pt')\n",
        "\n",
        "    print(f'Epoch: {epoch+1:02}')\n",
        "    print(f'\\tTrain Loss: {train_loss:.3f}\\tTrain PPL: {np.exp(train_loss):7.3f}')\n",
        "    print(f'\\t Validation Loss: {valid_loss:.3f}\\tValidation PPL: {np.exp(valid_loss):7.3f}')\n",
        "\n",
        "    epoch_info_list.append(f'Epoch: {epoch+1:02}, Train Loss: {train_loss:.3f}, Train PPL: {np.exp(train_loss):7.3f}, Validation Loss:{valid_loss:.3f}, Validation PPL: {np.exp(valid_loss):7.3f}')\n",
        ""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch_info in epoch_info_list:\n",
        "  print(epoch_info)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RLvwIo3SJBFi",
        "outputId": "7648bcc9-40ad-45ee-8b06-7ed494fd6119"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 01, Train Loss: 10.688, Train PPL: 43816.560, Validation Loss:10.685, Validation PPL: 43682.609\n",
            "Epoch: 02, Train Loss: 10.688, Train PPL: 43815.816, Validation Loss:10.685, Validation PPL: 43682.609\n",
            "Epoch: 03, Train Loss: 10.688, Train PPL: 43819.184, Validation Loss:10.685, Validation PPL: 43682.609\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "meHcb9oOi_YN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2c8bc3f6-506e-4c8a-cafd-62e8ca2a581a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hid torch.Size([2, 10, 512])\n",
            "hid torch.Size([2, 10, 512])\n",
            "hid torch.Size([2, 10, 512])\n",
            "hid torch.Size([2, 10, 512])\n",
            "hid torch.Size([2, 10, 512])\n",
            "hid torch.Size([2, 10, 512])\n",
            "hid torch.Size([2, 10, 512])\n",
            "hid torch.Size([2, 10, 512])\n",
            "hid torch.Size([2, 10, 512])\n",
            "hid torch.Size([2, 10, 512])\n",
            "hid torch.Size([2, 10, 512])\n",
            "hid torch.Size([2, 10, 512])\n",
            "hid torch.Size([2, 10, 512])\n",
            "hid torch.Size([2, 10, 512])\n",
            "hid torch.Size([2, 10, 512])\n",
            "hid torch.Size([2, 10, 512])\n",
            "hid torch.Size([2, 10, 512])\n",
            "hid torch.Size([2, 10, 512])\n",
            "hid torch.Size([2, 10, 512])\n",
            "hid torch.Size([2, 10, 512])\n",
            "hid torch.Size([2, 10, 512])\n",
            "hid torch.Size([2, 10, 512])\n",
            "hid torch.Size([2, 10, 512])\n",
            "hid torch.Size([2, 10, 512])\n",
            "hid torch.Size([2, 10, 512])\n",
            "hid torch.Size([2, 10, 512])\n",
            "hid torch.Size([2, 10, 512])\n",
            "hid torch.Size([2, 10, 512])\n",
            "hid torch.Size([2, 10, 512])\n",
            "hid torch.Size([2, 10, 512])\n",
            "hid torch.Size([2, 10, 512])\n",
            "hid torch.Size([2, 10, 512])\n",
            "hid torch.Size([2, 10, 512])\n",
            "hid torch.Size([2, 10, 512])\n",
            "hid torch.Size([2, 10, 512])\n",
            "hid torch.Size([2, 10, 512])\n",
            "hid torch.Size([2, 10, 512])\n",
            "hid torch.Size([2, 10, 512])\n",
            "hid torch.Size([2, 10, 512])\n",
            "hid torch.Size([2, 10, 512])\n",
            "hid torch.Size([2, 10, 512])\n",
            "hid torch.Size([2, 10, 512])\n",
            "hid torch.Size([2, 10, 512])\n",
            "hid torch.Size([2, 10, 512])\n",
            "hid torch.Size([2, 10, 512])\n",
            "hid torch.Size([2, 10, 512])\n",
            "hid torch.Size([2, 7, 512])\n",
            "\tTest Loss: 10.684\tTest PPL: 43634.714\n"
          ]
        }
      ],
      "source": [
        "#NOTE: load model from file\n",
        "model.load_state_dict(torch.load('model.pt'))\n",
        "\n",
        "test_loss = evaluate(model, test_iter, criterion)\n",
        "\n",
        "print(f'\\tTest Loss: {test_loss:.3f}\\tTest PPL: {np.exp(test_loss):7.3f}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "g7dql_q_i_YN"
      },
      "outputs": [],
      "source": [
        "#clean mem\n",
        "del model\n",
        "del train_iter\n",
        "del valid_iter\n",
        "del test_iter\n",
        "torch.cuda.empty_cache()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "BLEU added\n",
        "\n",
        "Seconadly, I have been training the model with BLEU score addded, with tranining data size = 1000, batch size =10, num of epoch = 3 and Luong attention\n"
      ],
      "metadata": {
        "id": "4vtENJ0x1XAF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torchtext.data.metrics import bleu_score\n",
        "\n",
        "def calculate_bleu(model, iterator, src_vocab, trg_vocab, device):\n",
        "    model.eval()\n",
        "    trgs = []\n",
        "    pred_trgs = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for src, trg in iterator:\n",
        "            src = src.to(device)\n",
        "            trg = trg.to(device)\n",
        "\n",
        "            output = model(src, trg, 0)  # no teacher forcing\n",
        "            output_dim = output.shape[-1]\n",
        "\n",
        "            output = output.argmax(-1)  # [trg_len, batch_size] finds the index of the most likely token across the last dimension (output_dim)\n",
        "\n",
        "            for i in range(trg.shape[1]):\n",
        "                trg_sent = [trg_vocab.lookup_tokens(trg[1:, i])]\n",
        "                pred_sent = trg_vocab.lookup_tokens(output[1:, i])\n",
        "\n",
        "                \"\"\"\n",
        "                def lookup_tokens(self, indices: List[int]) -> List[str]:r\n",
        "                Args:indices: The `indices` used to lookup their corresponding`tokens`.\n",
        "                Returns: The `tokens` associated with `indices`.\n",
        "                Raises: RuntimeError: If an index within `indices` is not int range [0, itos.size()).\n",
        "                     return self.vocab.lookup_tokens(indices)\n",
        "                \"\"\"\n",
        "\n",
        "                # remove padding and EOS tokens from predictions\n",
        "                pred_sent = [token for token in pred_sent if token not in ['<pad>', '<eos>']]\n",
        "\n",
        "                trgs.append(trg_sent)\n",
        "                pred_trgs.append(pred_sent)\n",
        "\n",
        "    return bleu_score(pred_trgs, trgs)"
      ],
      "metadata": {
        "id": "j_BOAG1l1THS"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "N_EPOCHS = 3\n",
        "CLIP = 1\n",
        "\n",
        "best_valid_loss = float('inf')\n",
        "best_valid_bleu = 0.0\n",
        "\n",
        "epoch_info_list_bleu = []\n",
        "\n",
        "for epoch in range(N_EPOCHS):\n",
        "\n",
        "    train_loss = train(model, train_iter, optimizer, criterion, CLIP, device)\n",
        "    valid_loss = evaluate(model, valid_iter, criterion, device)\n",
        "    valid_bleu = calculate_bleu(model, valid_iter, SRC.vocab, TRG.vocab, device)\n",
        "\n",
        "    # Check both BLEU and validation loss for model saving (you can pick either)\n",
        "    if valid_bleu > best_valid_bleu:\n",
        "        best_valid_bleu = valid_bleu\n",
        "        torch.save(model.state_dict(), 'model_best_bleu.pt')\n",
        "\n",
        "    if valid_loss < best_valid_loss:\n",
        "        best_valid_loss = valid_loss\n",
        "        torch.save(model.state_dict(), 'model_best_loss.pt')\n",
        "\n",
        "    print(f'Epoch: {epoch+1:02}')\n",
        "    print(f'\\tTrain Loss: {train_loss:.3f}\\tTrain PPL: {np.exp(train_loss):7.3f}')\n",
        "    print(f'\\tValidation Loss: {valid_loss:.3f}\\tValidation PPL: {np.exp(valid_loss):7.3f}')\n",
        "    print(f'\\tValidation BLEU Score: {valid_bleu*100:.2f}')\n",
        "\n",
        "\n",
        "    epoch_info_list_bleu.append(f'Epoch: {epoch+1:02}, Train Loss: {train_loss:.3f}, Train PPL: {np.exp(train_loss):7.3f}, Validation Loss:{valid_loss:.3f}, Validation PPL: {np.exp(valid_loss):7.3f}, Validation BLEU Score: {valid_bleu*100:.2f}')"
      ],
      "metadata": {
        "id": "Aq0gjsFK10Op",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 219
        },
        "outputId": "aa29f65f-27a5-47af-e7f9-d4d8af36b8e0"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'model' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-48-5d877571c01a>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mN_EPOCHS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0mtrain_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_iter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCLIP\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m     \u001b[0mvalid_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_iter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0mvalid_bleu\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcalculate_bleu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_iter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSRC\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocab\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTRG\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocab\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6LBvQ-ov13lF"
      },
      "outputs": [],
      "source": [
        "#NOTE: load model from file\n",
        "#model.load_state_dict(torch.load('model.pt'))\n",
        "\n",
        "test_loss = evaluate(model, test_iter, criterion)\n",
        "\n",
        "print(f'\\tTest Loss: {test_loss:.3f}\\tTest PPL: {np.exp(test_loss):7.3f}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4OkqZLMm13lF"
      },
      "outputs": [],
      "source": [
        "#clean mem\n",
        "del model\n",
        "del train_iter\n",
        "del valid_iter\n",
        "del test_iter\n",
        "torch.cuda.empty_cache()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}